{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, GlobalAveragePooling1D, UpSampling1D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.cross_validation import KFold\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the random seeds\n",
    "random.seed(1)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "\n",
    "# Description: This function is responsible for loading our data.\n",
    "# Args in: filepath - the path of the .mat file containing the data\n",
    "# Returns: inputs - the data, labels - the labels corresponding to the data, \n",
    "#            patients - the patients corresponding to the data\n",
    "\n",
    "    mat = scipy.io.loadmat(filepath)\n",
    "    inputs = mat['U0_new'][:]\n",
    "    labels = mat['Y']\n",
    "    patients = mat['patientID']\n",
    "\n",
    "    labels = np.einsum('ij->ji', labels)\n",
    "    labels = [label for sublist in labels for label in sublist]\n",
    "    patients = np.einsum('ij->ji', patients)\n",
    "    patients = [patient for sublist in patients for patient in sublist]\n",
    "\n",
    "    return inputs, labels, patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_non_frail(inputs, labels, patients):\n",
    "\n",
    "#Description: This function allows us to access specifically the data corresponding to the patients\n",
    "#that are labeled as being not frail.\n",
    "#Args in & Returns are self-explanatory.\n",
    "    \n",
    "    first_pre_frail_index = labels.index(1)\n",
    "    last_pre_frail_index = len(labels) - 1 - labels[::-1].index(1)\n",
    "    \n",
    "    inputs = np.asarray(list(inputs[:first_pre_frail_index]))\n",
    "    labels = np.asarray(list(labels[:first_pre_frail_index]))\n",
    "    patients = np.asarray(list(patients[:first_pre_frail_index]))\n",
    "    \n",
    "    assert(np.unique(labels) == [0])\n",
    "    \n",
    "    return inputs, labels, patients\n",
    "\n",
    "def get_pre_frail(inputs, labels, patients):\n",
    "\n",
    "# Description: Symmetric to the function above.\n",
    "# Args in & Returns are self-explanatory.\n",
    "    \n",
    "    first_pre_frail_index = labels.index(1)\n",
    "    last_pre_frail_index = len(labels) - 1 - labels[::-1].index(1)\n",
    "    \n",
    "    inputs = np.asarray(list(inputs[first_pre_frail_index:last_pre_frail_index+1]))\n",
    "    labels = np.asarray(list(labels[first_pre_frail_index:last_pre_frail_index+1]))\n",
    "    patients = np.asarray(list(patients[first_pre_frail_index:last_pre_frail_index+1]))\n",
    "    \n",
    "    assert(np.unique(labels) == [1])\n",
    "    \n",
    "    return inputs, labels, patients\n",
    "\n",
    "def get_frail(inputs, labels, patients):\n",
    " \n",
    "# Description: Symmetric to the function above.\n",
    "# Args in & Returns are self-explanatory.\n",
    "    \n",
    "    first_pre_frail_index = labels.index(1)\n",
    "    last_pre_frail_index = len(labels) - 1 - labels[::-1].index(1)\n",
    "    \n",
    "    inputs = np.asarray(list(inputs[last_pre_frail_index+1:]))\n",
    "    labels = np.asarray(list(labels[last_pre_frail_index+1:]))\n",
    "    patients = np.asarray(list(patients[last_pre_frail_index+1:]))\n",
    "    \n",
    "    assert(np.unique(labels) == [2])\n",
    "    \n",
    "    return inputs, labels, patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_duplicates(duplicates_list, inputs, targets, patients):\n",
    "\n",
    "# Description: This function is responsible for filtering out\n",
    "# some patients that are found to be present in more than one classes.\n",
    "# Args in & Returns are self-explanatory.\n",
    "    \n",
    "    patients = list(patients)\n",
    "    \n",
    "    duplicate_indices = []\n",
    "    for duplicate in duplicates_list:\n",
    "        #patients = list(filter(lambda a: a != duplicate, patients))\n",
    "        for i in range(len(patients)):\n",
    "            if patients[i] == duplicate:\n",
    "                duplicate_indices.append(i)\n",
    "    \n",
    "    duplicate_indices = set(duplicate_indices)\n",
    "    all_indices = set([i for i in range(len(patients))])\n",
    "    valid_indices = set(all_indices - duplicate_indices)\n",
    "    inputs = [inputs[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    patients = [patients[i] for i in valid_indices]\n",
    "    \n",
    "    return inputs, targets, np.asarray(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, labels, patients = load_data('/Users/Nikos/Desktop/MyResearch/Zacharaki/PARAFACmissingvalues0_90/ReconstructedTensorAndFeatures90Missing_StrSGD.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1006 1007 1012 1035 1042 1044 1049 1050 1053 1086 1091 1092 1093 1095 1098\n",
      " 1099 1102 1103 1106 1108 1113 1114 1115 1118 1510 1514 2050 2087 2108 2111\n",
      " 2119 2615 3006 3033 3039 3052 3062 3070 3076 3082 3086 3087 3095 3099 3104\n",
      " 3106 3113 3117 3550]\n",
      "[2006 2082 2094 2097 2104 2109 2116 2584 3035]\n",
      "[1003 1005 1013 1017 1027 1047 1052 1054 1056 1057 1059 1063 1090 1094 1100\n",
      " 1101 1107 1109 1110 1119 1120 1558 2005 2057 2070 2073 2081 2083 2085 2089\n",
      " 2090 2091 2092 2095 2098 2100 2101 2102 2103 2105 2107 2110 2113 3026 3034\n",
      " 3043 3084 3085 3098 3112 3525 3559 3578 3592 3593 3601]\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, patients = filter_duplicates([1002, 1104], inputs, labels, patients)\n",
    "#print(inputs.shape, labels.shape, patients.shape)\n",
    "non_frail_inputs, non_frail_labels, non_frail_patients = get_non_frail(inputs, labels, patients)\n",
    "pre_frail_inputs, pre_frail_labels, pre_frail_patients = get_pre_frail(inputs, labels, patients)\n",
    "frail_inputs, frail_labels, frail_patients = get_frail(inputs, labels, patients)\n",
    "\n",
    "print(np.unique(non_frail_patients))\n",
    "print(np.unique(frail_patients))\n",
    "print(np.unique(pre_frail_patients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we hereby start by loading the data and break them in non_frail, pre_frail and frail containers for future use. We are going to need the separation in order to build three autoencoder models, one corresponding to each of the classes in our data. We will then split our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(inputs, targets, patients, patients_for_test):\n",
    "\n",
    "# Description: This function is responsible for splitting our data into training and test data\n",
    "# Args in: patients_for_val - list containing the patients for our test data\n",
    "# Returns: the data and labels of our training and test data\n",
    "\n",
    "    X_train_size = X_test_size = 0\n",
    "\n",
    "    patients_for_train = [item for item in list(np.unique(patients)) if item not in patients_for_test]\n",
    "    idpatients_test = []\n",
    "    for patient in patients_for_test:\n",
    "        idpatient = [i for i, x in enumerate(patients) if x == patient]\n",
    "        idpatients_test.append(idpatient)\n",
    "    idpatients_test = [item for sublist in idpatients_test for item in sublist]\n",
    "    X_test = [inputs[i] for i in idpatients_test]\n",
    "    y_test = [targets[i] for i in idpatients_test]\n",
    "    patients_test = [patients[i] for i in idpatients_test]\n",
    "    \n",
    "    #print(inputs.shape)\n",
    "    idpatients_train = list(set([i for i in range(inputs.shape[0])]) - set(idpatients_test))\n",
    "    #print(idpatients_train)\n",
    "    inputs = [inputs[i] for i in idpatients_train]\n",
    "    targets = [targets[i] for i in idpatients_train]\n",
    "    patients_train = [patients[i] for i in idpatients_train]\n",
    "    \n",
    "    return np.asarray(inputs), np.asarray(targets), np.asarray(patients_train), np.asarray(X_test), np.asarray(y_test), np.asarray(patients_test)\n",
    "\n",
    "def split_train_val(inputs, targets, patients, patients_for_val):\n",
    "\n",
    "# Description: This function is responsible for splitting our data into training and validation data\n",
    "# Args in: patients_for_val - list containing the patients for our validation data\n",
    "# Returns: the data and labels of our training and validation data\n",
    "\n",
    "    X_train_size = X_val_size = 0\n",
    "\n",
    "    patients_for_train = [item for item in list(np.unique(patients)) if item not in patients_for_val]\n",
    "    idpatients_val = []\n",
    "    for patient in patients_for_val:\n",
    "        idpatient = [i-1 for i, x in enumerate(patients) if x == patient]\n",
    "        idpatients_val.append(idpatient)\n",
    "    idpatients_val = [item for sublist in idpatients_val for item in sublist]\n",
    "    X_val = [inputs[i] for i in idpatients_val]\n",
    "    y_val = [targets[i] for i in idpatients_val]\n",
    "    \n",
    "    idpatients_train = list(set([i for i in range(inputs.shape[0])]) - set(idpatients_val))\n",
    "    inputs = [inputs[i] for i in idpatients_train]\n",
    "    y_train = [targets[i] for i in idpatients_train]\n",
    "\n",
    "    return np.asarray(inputs), np.asarray(X_val), np.asarray(inputs), np.asarray(X_val), np.asarray(y_train), np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6478, 60) (5, 60) (645, 60)\n",
      "(6478,) (5,) (645,)\n",
      "(8295, 60) (32, 60) (13, 60)\n",
      "(8295,) (32,) (13,)\n",
      "(1783, 60) (296, 60) (735, 60)\n",
      "(1783,) (296,) (735,)\n"
     ]
    }
   ],
   "source": [
    "X_train_non_frail, y_train_non_frail, patients_train_non_frail, X_test_non_frail, y_test_non_frail, patients_test_non_frail = split_train_test(\n",
    "    non_frail_inputs, non_frail_labels, non_frail_patients, [1106, 1107, 2097])\n",
    "\n",
    "X_train_pre_frail, y_train_pre_frail, patients_train_pre_frail, X_test_pre_frail, y_test_pre_frail, patients_test_pre_frail = split_train_test(pre_frail_inputs, \n",
    "                                                                                            pre_frail_labels, \n",
    "                                                                                            pre_frail_patients, \n",
    "                                                                                         [1106, 1107, 2097])\n",
    "\n",
    "X_train_frail, y_train_frail, patients_train_frail, X_test_frail, y_test_frail, patients_test_frail = split_train_test(frail_inputs, \n",
    "                                                                            frail_labels, \n",
    "                                                                            frail_patients, \n",
    "                                                                            [1106, 1107, 2097])\n",
    "\n",
    "X_train_non_frail, X_val_non_frail, train_ground_non_frail, valid_ground_non_frail, y_train_non_frail, y_val_non_frail = split_train_val(X_train_non_frail, y_train_non_frail, patients_train_non_frail, [1006])\n",
    "\n",
    "X_train_pre_frail, X_val_pre_frail, train_ground_pre_frail, valid_ground_pre_frail, y_train_pre_frail, y_val_pre_frail = split_train_val(X_train_pre_frail, y_train_pre_frail, patients_train_pre_frail, [3026])\n",
    "\n",
    "X_train_frail, X_val_frail, train_ground_frail, valid_ground_frail, y_train_frail, y_val_frail = split_train_val(X_train_frail, y_train_frail, patients_train_frail, [2104])\n",
    "\n",
    "print(X_train_non_frail.shape, X_val_non_frail.shape, X_test_non_frail.shape)\n",
    "print(y_train_non_frail.shape, y_val_non_frail.shape, y_test_non_frail.shape)\n",
    "\n",
    "print(X_train_pre_frail.shape, X_val_pre_frail.shape, X_test_pre_frail.shape)\n",
    "print(y_train_pre_frail.shape, y_val_pre_frail.shape, y_test_pre_frail.shape)\n",
    "\n",
    "print(X_train_frail.shape, X_val_frail.shape, X_test_frail.shape)\n",
    "print(y_train_frail.shape, y_val_frail.shape, y_test_frail.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def preprocess_data(X_train, X_val, X_test):\n",
    "\n",
    "# Description: This function preprocesses our data. \n",
    "# We want to ensure that our training data have zero mean and unit variance. \n",
    "# We also use subtract the same mean from the test data and then devide them by\n",
    "# the same standard deviation. We do that to ensure that no information about the\n",
    "# test set distribution is known ahead of time.\n",
    "\n",
    "# Args in & Returns are self-explanatory.\n",
    "    #scalers = {}\n",
    "    scaler = StandardScaler()\n",
    "    \"\"\"\n",
    "    for i in range(X_train.shape[2]):\n",
    "        scalers[i] = StandardScaler()\n",
    "        X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :])\n",
    "    \n",
    "    for i in range(X_test.shape[2]):\n",
    "        X_val[:, i, :] = scalers[i].transform(X_val[:, i, :]) \n",
    "        \n",
    "    for i in range(X_test.shape[2]):\n",
    "        X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) \n",
    "    \"\"\"\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis = 0)\n",
    "    \n",
    "    #X_val = (X_val - np.mean(X_train, axis=0)) / np.std(X_train, axis = 0)\n",
    "    \n",
    "    #X_test = (X_test -  np.mean(X_train, axis=0)) / np.std(X_train, axis = 0)\n",
    "    \n",
    "    #X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n",
    "    #X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1] * X_train.shape[2]))\n",
    "    #X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1] * X_val.shape[2]))\n",
    "    \n",
    "    return X_train, X_val, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_frail, X_val_non_frail, train_ground_non_frail, valid_ground_non_frail, X_test_non_frail = preprocess_data(X_train_non_frail, X_val_non_frail, X_test_non_frail)\n",
    "\n",
    "X_train_pre_frail, X_val_pre_frail, train_ground_pre_frail, valid_ground_pre_frail, X_test_pre_frail = preprocess_data(X_train_pre_frail, X_val_pre_frail, X_test_pre_frail)\n",
    "\n",
    "X_train_frail, X_val_frail, train_ground_frail, valid_ground_frail, X_test_frail = preprocess_data(X_train_frail, X_val_frail, X_test_frail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define our models. Each model will be an autoencoder trained with the training instances of a single class, so that we can end up with three autoencoders, each one building a (hopefully) useful representation of the class, the instances of which it was trained with. Since we want to use these models for feature extraction and, at the same time, dimensionality reduction we're going to use the intermediate layer (the encoder) to get features vectors that are way smaller in size than the raw vectors we started with. Hopefully, the compressed information these feature vectors contain will be (almost) equally valuable to the information encapsulated in the original data.\n",
    "\n",
    "Our autoencoder model will be the simplest possible, with just one hidden layer containing $32$ neurons acting as the encoder. This means that the model is going to learn 2 things: a function that is able to map our input of shape $1500$ (number-of-time-steps) * $7$ (number-of-channels) = $10500$ to a latent space of shape 32 and then a function which maps this latent space into the original space again, thus trying to recreate the original data. The best way to understand how the autoencoder works is thinking of a bottleneck which enforces our model to try and keep just the essential parts of the data needed for their recreation.\n",
    "\n",
    "We're going to train each model using the Adam optimizer with a learning rate of $0.0001$ for $30$ epochs, using a batch size of $128$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n",
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.9774119854\n",
      "0.3 2.9774119854\n",
      "0.1 2.9774119854\n",
      "0.03 2.9774119854\n",
      "0.01 2.9774119854\n",
      "0.003 2.9774119854\n",
      "0.001 2.9774119854\n",
      "0.0003 2.9774119854\n",
      "0.0001 2.9774119854\n",
      "3e-05 2.9774119854\n",
      "1e-05 2.9774119854\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1.0, 0.3, 0.1, 0.03, 0.01, 0.003, 0.001, 0.0003, 0.0001, 0.00003, 0.00001]\n",
    "\n",
    "input_signal = Input(shape = (X_train_non_frail.shape[1],))\n",
    "encoded_non_frail = Dense(32, activation = 'relu')(input_signal)\n",
    "\n",
    "# decoder\n",
    "decoded_non_frail = Dense(60, activation = 'sigmoid')(encoded_non_frail)\n",
    "\n",
    "autoencoder_non_frail = Model(input = input_signal, output = decoded_non_frail)\n",
    "\n",
    "non_frail_encoder = Model(input = input_signal, output = encoded_non_frail)\n",
    "non_frail_encoded_input = Input(shape=(32,))\n",
    "non_frail_decoder_layer = autoencoder_non_frail.layers[-1]\n",
    "non_frail_decoder = Model(non_frail_encoded_input, non_frail_decoder_layer(non_frail_encoded_input))\n",
    "\n",
    "# heuristic for learning rate\n",
    "for lr in learning_rates:\n",
    "    adam = Adam(lr = lr)\n",
    "    autoencoder_non_frail.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['mse'])\n",
    "    hist = autoencoder_non_frail.fit(X_train_non_frail, train_ground_non_frail, epochs=20, batch_size=128, \n",
    "                                    validation_data=(X_val_non_frail, valid_ground_non_frail), verbose=0, shuffle=True)\n",
    "    print(lr, hist.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1952      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                1980      \n",
      "=================================================================\n",
      "Total params: 3,932\n",
      "Trainable params: 3,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder_non_frail.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['mse'])\n",
    "print(autoencoder_non_frail.summary())\n",
    "history = autoencoder_non_frail.fit(X_train_non_frail, train_ground_non_frail, epochs=30, batch_size=128, \n",
    "                                    validation_data=(X_val_non_frail, valid_ground_non_frail), verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we're just uniting the feature vectors for the training set, extracted by just our encoder layer.\n",
    "encoder_non_frail_X_train = [non_frail_encoder.predict(X_train_non_frail), \n",
    "                             non_frail_encoder.predict(X_train_pre_frail), \n",
    "                             non_frail_encoder.predict(X_train_frail), \n",
    "                            ]\n",
    "encoder_non_frail_X_train = [i for sublist in encoder_non_frail_X_train for i in sublist]\n",
    "encoder_non_frail_X_test = [non_frail_encoder.predict(X_val_non_frail),\n",
    "                            non_frail_encoder.predict(X_val_pre_frail),\n",
    "                            non_frail_encoder.predict(X_val_frail),\n",
    "                            non_frail_encoder.predict(X_test_non_frail),\n",
    "                            non_frail_encoder.predict(X_test_pre_frail),\n",
    "                            non_frail_encoder.predict(X_test_frail)\n",
    "                           ]\n",
    "encoder_non_frail_X_test = [i for sublist in encoder_non_frail_X_test for i in sublist]\n",
    "\n",
    "encoder_non_frail_X_train = np.asarray(encoder_non_frail_X_train)\n",
    "encoder_non_frail_X_test = np.asarray(encoder_non_frail_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n",
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.03642749786\n",
      "0.3 1.04035162926\n",
      "0.1 1.04035162926\n",
      "0.03 1.04035162926\n",
      "0.01 1.04035162926\n",
      "0.003 1.04035162926\n",
      "0.001 1.04035162926\n",
      "0.0003 1.04035162926\n",
      "0.0001 1.04035162926\n",
      "3e-05 1.04035162926\n",
      "1e-05 1.04035162926\n"
     ]
    }
   ],
   "source": [
    "input_signal = Input(shape = (X_train_pre_frail.shape[1],))\n",
    "encoded_pre_frail = Dense(32, activation = 'relu')(input_signal)\n",
    "\n",
    "# decoder\n",
    "decoded_pre_frail = Dense(60, activation = 'sigmoid')(encoded_pre_frail)\n",
    "\n",
    "autoencoder_pre_frail = Model(input = input_signal, output = decoded_pre_frail)\n",
    "\n",
    "pre_frail_encoder = Model(input = input_signal, output = encoded_pre_frail)\n",
    "pre_frail_encoded_input = Input(shape=(32,))\n",
    "pre_frail_decoder_layer = autoencoder_pre_frail.layers[-1]\n",
    "pre_frail_decoder = Model(pre_frail_encoded_input, pre_frail_decoder_layer(pre_frail_encoded_input))\n",
    "\n",
    "# heuristic for learning rate\n",
    "\n",
    "for lr in learning_rates:\n",
    "    adam = Adam(lr = lr)\n",
    "    autoencoder_pre_frail.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['mse'])\n",
    "    hist = autoencoder_pre_frail.fit(X_train_pre_frail, train_ground_pre_frail, epochs=20, batch_size=128, \n",
    "                                    validation_data=(X_val_pre_frail, valid_ground_pre_frail), verbose=0, shuffle=True)\n",
    "    print(lr, hist.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1952      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 60)                1980      \n",
      "=================================================================\n",
      "Total params: 3,932\n",
      "Trainable params: 3,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder_pre_frail.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['mse'])\n",
    "print(autoencoder_pre_frail.summary())\n",
    "history = autoencoder_pre_frail.fit(X_train_pre_frail, train_ground_pre_frail, epochs=20, batch_size=128, \n",
    "                                    validation_data=(X_val_pre_frail, valid_ground_pre_frail), verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_pre_frail_X_train = [pre_frail_encoder.predict(X_train_non_frail), \n",
    "                             pre_frail_encoder.predict(X_train_pre_frail), \n",
    "                             pre_frail_encoder.predict(X_train_frail), \n",
    "                            ]\n",
    "encoder_pre_frail_X_train = [i for sublist in encoder_pre_frail_X_train for i in sublist]\n",
    "encoder_pre_frail_X_test = [pre_frail_encoder.predict(X_val_non_frail),\n",
    "                            pre_frail_encoder.predict(X_val_pre_frail),\n",
    "                            pre_frail_encoder.predict(X_val_frail),\n",
    "                            pre_frail_encoder.predict(X_test_non_frail),\n",
    "                            pre_frail_encoder.predict(X_test_pre_frail),\n",
    "                            pre_frail_encoder.predict(X_test_frail)\n",
    "                           ]\n",
    "encoder_pre_frail_X_test = [i for sublist in encoder_pre_frail_X_test for i in sublist]\n",
    "\n",
    "encoder_pre_frail_X_train = np.asarray(encoder_pre_frail_X_train)\n",
    "encoder_pre_frail_X_test = np.asarray(encoder_pre_frail_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n",
      "/Users/Nikos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.97390748198\n",
      "0.3 0.97390748198\n",
      "0.1 0.97390748198\n",
      "0.03 0.97390748198\n",
      "0.01 0.97390748198\n",
      "0.003 0.97390748198\n",
      "0.001 0.97390748198\n",
      "0.0003 0.97390748198\n",
      "0.0001 0.97390748198\n",
      "3e-05 0.97390748198\n",
      "1e-05 0.97390748198\n"
     ]
    }
   ],
   "source": [
    "input_signal = Input(shape = (X_train_frail.shape[1],))\n",
    "encoded_frail = Dense(32, activation = 'relu')(input_signal)\n",
    "\n",
    "# decoder\n",
    "decoded_frail = Dense(60, activation = 'sigmoid')(encoded_frail)\n",
    "\n",
    "autoencoder_frail = Model(input = input_signal, output = decoded_frail)\n",
    "\n",
    "frail_encoder = Model(input = input_signal, output = encoded_frail)\n",
    "frail_encoded_input = Input(shape=(32,))\n",
    "frail_decoder_layer = autoencoder_frail.layers[-1]\n",
    "frail_decoder = Model(frail_encoded_input, frail_decoder_layer(frail_encoded_input))\n",
    "\n",
    "for lr in learning_rates:\n",
    "    adam = Adam(lr = lr)\n",
    "    autoencoder_frail.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['mse'])\n",
    "    hist = autoencoder_frail.fit(X_train_frail, train_ground_frail, epochs=20, batch_size=128, \n",
    "                                    validation_data=(X_val_frail, valid_ground_frail), verbose=0, shuffle=True)\n",
    "    print(lr, hist.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1952      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 60)                1980      \n",
      "=================================================================\n",
      "Total params: 3,932\n",
      "Trainable params: 3,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder_frail.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['mse'])\n",
    "print(autoencoder_frail.summary())\n",
    "history = autoencoder_frail.fit(X_train_frail, train_ground_frail, epochs=30, batch_size=128, \n",
    "                                    validation_data=(X_val_frail, valid_ground_frail), verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_frail_X_train = [frail_encoder.predict(X_train_non_frail), \n",
    "                             frail_encoder.predict(X_train_pre_frail), \n",
    "                             frail_encoder.predict(X_train_frail), \n",
    "                            ]\n",
    "encoder_frail_X_train = [i for sublist in encoder_frail_X_train for i in sublist]\n",
    "encoder_frail_X_test = [frail_encoder.predict(X_val_non_frail),\n",
    "                            frail_encoder.predict(X_val_pre_frail),\n",
    "                            frail_encoder.predict(X_val_frail),\n",
    "                            frail_encoder.predict(X_test_non_frail),\n",
    "                            frail_encoder.predict(X_test_pre_frail),\n",
    "                            frail_encoder.predict(X_test_frail)\n",
    "                           ]\n",
    "encoder_frail_X_test = [i for sublist in encoder_frail_X_test for i in sublist]\n",
    "\n",
    "encoder_frail_X_train = np.asarray(encoder_frail_X_train)\n",
    "encoder_frail_X_test = np.asarray(encoder_frail_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're just building the training and test set consisting of the features extracted by our encoder models in order to use them for classification purposes, using some simple machine learning classifier like kNN or SVM. Each of our features will consist of the concatenated feature vectors of each encoder, thus producing a feature vector consisting of $32$ + $32$ + $32$ = $96$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16556, 64) (16556, 32) (16556, 32) (16556, 32)\n",
      "(16556, 96)\n",
      "(1726, 96)\n",
      "(16556, 96) (1726, 96)\n",
      "(16556,) (1726,)\n"
     ]
    }
   ],
   "source": [
    "final_X_train = np.concatenate((encoder_non_frail_X_train, encoder_pre_frail_X_train), axis = 1)\n",
    "print(final_X_train.shape, encoder_frail_X_train.shape, encoder_non_frail_X_train.shape, encoder_pre_frail_X_train.shape)\n",
    "final_X_train = np.concatenate((final_X_train, encoder_frail_X_train), axis = 1)\n",
    "print(final_X_train.shape)\n",
    "final_X_test = np.concatenate((encoder_non_frail_X_test , encoder_pre_frail_X_test ), axis = 1)\n",
    "final_X_test = np.concatenate((final_X_test, encoder_frail_X_test), axis = 1)\n",
    "print(final_X_test.shape)\n",
    "\n",
    "\n",
    "encoder_y_train = [y_train_non_frail, y_train_pre_frail, y_train_frail]\n",
    "encoder_y_test = [y_val_non_frail, y_val_pre_frail, y_val_frail, y_test_non_frail, y_test_pre_frail, y_test_frail]\n",
    "\n",
    "encoder_y_train = [i for sublist in encoder_y_train for i in sublist]\n",
    "encoder_y_test = [i for sublist in encoder_y_test for i in sublist]\n",
    "encoder_y_train = np.asarray(encoder_y_train)\n",
    "encoder_y_test = np.asarray(encoder_y_test)\n",
    "\n",
    "c = list(zip(final_X_train, encoder_y_train))\n",
    "random.shuffle(c)\n",
    "final_X_train, final_y_train = zip(*c)\n",
    "\n",
    "c = list(zip(final_X_test, encoder_y_test))\n",
    "random.shuffle(c)\n",
    "final_X_test, final_y_test = zip(*c)\n",
    "\n",
    "final_X_train = np.asarray(final_X_train)\n",
    "final_X_test = np.asarray(final_X_test)\n",
    "print(final_X_train.shape, final_X_test.shape)\n",
    "print(encoder_y_train.shape, encoder_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to run an initial experiment on the data we created by simply using a kNN classifier with the default parameters. The results of this experiment are good but not the best. Maybe with some hyperparameter tuning we can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(final_X_train, final_y_train)\n",
    "preds = neigh.predict(final_X_test)\n",
    "print(\"Accuracy score %.2f\"%(accuracy_score(preds, final_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 8}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.662 (+/-0.023) for {'n_neighbors': 2}\n",
      "0.646 (+/-0.010) for {'n_neighbors': 3}\n",
      "0.645 (+/-0.013) for {'n_neighbors': 4}\n",
      "0.665 (+/-0.010) for {'n_neighbors': 5}\n",
      "0.666 (+/-0.010) for {'n_neighbors': 6}\n",
      "0.664 (+/-0.011) for {'n_neighbors': 7}\n",
      "0.670 (+/-0.014) for {'n_neighbors': 8}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikos/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      1.00      0.76       645\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.00      0.00      0.00       399\n",
      "\n",
      "avg / total       0.37      0.61      0.46      1057\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 7}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.552 (+/-0.011) for {'n_neighbors': 2}\n",
      "0.596 (+/-0.005) for {'n_neighbors': 3}\n",
      "0.587 (+/-0.011) for {'n_neighbors': 4}\n",
      "0.594 (+/-0.007) for {'n_neighbors': 5}\n",
      "0.600 (+/-0.011) for {'n_neighbors': 6}\n",
      "0.601 (+/-0.006) for {'n_neighbors': 7}\n",
      "0.597 (+/-0.008) for {'n_neighbors': 8}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      1.00      0.76       645\n",
      "          1       0.00      0.00      0.00        13\n",
      "          2       0.00      0.00      0.00       399\n",
      "\n",
      "avg / total       0.37      0.61      0.46      1057\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikos/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'n_neighbors': [2, 3, 4, 5, 6, 7, 8]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(final_X_train, final_y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = final_y_test, clf.predict(final_X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the above results a promising setting is to use the kNN classifier with the n_neighbors parameter set to 5. Indeed the results are way much better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEYCAYAAADLZOR0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xm81nP+//HHs44iIbSMTiktlhiS\nSogx1pAYX9kaimiymwZjHcvYjW0mM372XWQZyZIsEUNJdqFS0UJCkfbT6/fH+33V1XHOdV3nnOtc\ny+l173bdzvXZX9f1Ob3O+/15fz7vt8wM55xzQb18B+Ccc4XEk6JzziXxpOicc0k8KTrnXBJPis45\nl8STonPOJfGkWAFJ60l6RtICScNrsJ9+kl7MZmz5Iml3SZ8XyvEktZVkkkpyFVOxkDRd0j7x/QWS\n7qyFY9wm6eJs77cQqJjvU5R0DDAE2Br4GXgfuNLM3qjhfo8FTgd2NbMVNQ60wEkyoKOZTcl3LJWR\nNB040cxeitNtgWnAOtk+R5LuBWaa2UXZ3G+ulP+usrC/AXF/PbOxv0JXtCVFSUOAm4GrgBbA5sC/\ngUOysPs2wBdrQ0LMhJfGao9/twXIzIruBWwELAT6plinISFpzo6vm4GGcdmewEzgL8BcYA5wfFx2\nGbAMWB6PMRC4FHgwad9tAQNK4vQA4EtCaXUa0C9p/htJ2+0KvAMsiD93TVo2Bvg78Gbcz4tA00o+\nWyL+c5PiPxQ4EPgC+AG4IGn97sBbwPy47lCgQVz2evwsv8TPe2TS/v8KfAM8kJgXt2kfj9ElTrcE\n5gF7ZnDu7gP+Et+XxmOfEqc7xP2q3PEeAFYCi2OM5yadg/7AV/H4F2Z4/tc4L3GexeMPiud+WTzW\nM5V8DgMGA5OBH4FbWV3zqgdcBMyI5+d+YKNyvzsDY9yvJ807Hvg67m8w0A34MJ63oUnHbg+8Anwf\nP/dDQJOk5dOBfeL7S4m/u/G8L0x6rQAujcvOA6YSfvc+Bf4Q528DLAHK4jbz4/x7gSuSjnkSMCWe\nvxFAy0y+q0J85T2AagUNveIJLUmxzuXA20BzoBnwP+DvcdmecfvLgXUIyWQRsHH5X6RKphO/xCXA\n+sBPwFZx2WbAtuX/8wGbxF+IY+N2R8fpTePyMfGXcktgvTh9TSWfLRH/32L8JwHfAQ8DGwDbxl/k\ndnH9nYAe8bhtgUnAWeUTQgX7v5aQXNYjKUkl/SeYBDQCRgH/yPDcnUBMNMAx8TM/mrTs6aQYko83\nnfgfvdw5uCPGtwOwFNgmg/O/6rxU9B1Q7j98JZ/DgJFAE0It5TugV9LnmAK0AxoDTwIPlIv7fsLv\nznpJ824D1gX2i+fvvzH+UkJy/V3cRwdg33humhES680VfVeU+91NWqdzjHnHON2X8MetHuEP4y/A\nZim+r1XfEbAXITl3iTH9C3g9k++qEF/FWn3eFJhnqau3/YDLzWyumX1HKAEem7R8eVy+3MyeI/wV\n3Kqa8awEtpO0npnNMbNPKljnIGCymT1gZivM7BHgM+DgpHXuMbMvzGwx8BjhF7cyywnXT5cDw4Cm\nwC1m9nM8/ifA9gBm9q6ZvR2POx34f8DvMvhMl5jZ0hjPGszsDsJf/nGEPwQXptlfwmvA7pLqAXsA\n1wG7xWW/i8ur4jIzW2xmHwAfEJIjpD//2XCNmc03s6+AV1l9vvoBN5rZl2a2EDgfOKpcVflSM/ul\n3Hf7dzNbYmYvEpLSIzH+WcBYYEcAM5tiZqPjufkOuJH053MVSc0ICfd0M3sv7nO4mc02s5Vm9ijh\n3HbPcJf9gLvNbKKZLY2fd5d43Tehsu+q4BRrUvweaJrmekxLQvUlYUact2of5ZLqIsJf9Soxs18I\nf1kHA3MkPStp6wziScRUmjT9TRXi+d7MyuL7xH+sb5OWL05sL2lLSSMlfSPpJ8J12KYp9g3wnZkt\nSbPOHcB2wL/if4a0zGwq4Q9QZ2B3QglitqStqF5SrOw7S3f+s6Eqxy4hXPtO+LqC/ZU/f5Wdz+aS\nhkmaFc/ng6Q/n8Rt1wEeBx42s2FJ84+T9L6k+ZLmE85rRvuk3OeNfwi+p/q/23lVrEnxLUL14tAU\n68wmNJgkbB7nVccvhGpiwm+SF5rZKDPbl1Bi+oyQLNLFk4hpVjVjqor/EOLqaGYbAhcQrtulkvK2\nBEmNCdfp7gIulbRJFeJ5DTiccF1zVpw+DtiYcAdBleOpQKrzv8b5lLTG+azGsTI59grWTHI1OcbV\ncfvt4/n8I+nPZ8K/CNcNV7WsS2pD+J09jXA5pwnwcdI+08W6xueVtD6hNpeL3+2sK8qkaGYLCNfT\nbpV0qKRGktaRdICk6+JqjwAXSWomqWlc/8FqHvJ9YA9Jm0vaiFA9AEBSC0l94i/CUkIpqKyCfTwH\nbCnpGEklko4EOhFKSrVtA8J1z4WxFHtyueXfEq5/VcUtwLtmdiLwLOF6GACSLpU0JsW2rxH+A74e\np8cQboF6I6n0W15VY0x1/j8AtpXUWdK6hOtuNTlWRcf+s6Qt4h+PqwjXTbN1N8MGxEYPSaXAOZls\nJOlPhNL4MWa2MmnR+oTE911c73hCSTHhW6CVpAaV7Pph4Pj4fTYkfN5x8VJN0SnKpAhgZjcS7lG8\niHAyvyb8R/tvXOUKYAKh9e4jYGKcV51jjQYejft6lzUTWT1CK/ZsQsvb74BTKtjH90DvuO73hBbU\n3mY2rzoxVdHZhEaNnwklgkfLLb8UuC9WnY5ItzNJhxAauwbHWUOALpL6xenWhFb0yrxG+I+dSIpv\nEEpur1e6RSgdXRRjPDtdjKQ4/2b2BaEh5iXCtbPy97XeBXSKx/ovVXc3ocX8dcLdCEsIST9bLiM0\naiwg/EF6MsPtjiYk+9mSFsbXBWb2KXADoQb2LfBb1jx/rxCuUX8j6Ve/r2b2MnAx8ATh7ob2wFHV\n+WCFoKhv3naFSdL7wN7xD4FzRcWTonPOJSna6rNzztUGT4rOOZfEk6JzziXxh9Er0bRpU2vTpm2+\nw8ib5WVr97Xmj2d4G5HNnzHPzJpla3/1N2xjtuJXD0eteczF340ys17ZOmZ1eFKsRJs2bXlz3IR8\nh5E33y5I9zBL3bbNnx7Odwh5t/iJgeWfwKoRW7GYhlulvuNryfu3ZvoUTa3xpOicyw0J6tXPdxRp\neVJ0zuWOCr8Zw5Oicy53lOkj2vnjSdE5lyNefXbOudWEV5+dc241efXZOefW4NVn55xLkFefnXNu\nFeHVZ+ecW01Qr/BTTuFH6JyrO+p5SdE554IiuSWn8CN0ztUR8ebtVK9M9iI1kfS4pM8kTZK0i6RN\nJI2WNDn+3DiuK0n/lDRF0oeSuqTbvydF51zuSKlfmbkFeMHMtgZ2ACYB5wEvm1lH4OU4DXAA0DG+\nBhGG+03Jk6JzLndUL/Ur3ebShsAehBEXMbNlZjYfOAS4L652H6vHhD8EuN+Ct4EmkjZLdQxPis65\n3FBG1eemkiYkvQaV20s7wpDG90h6T9Kdccz1FmY2ByD+bB7XLyUMf5wwM86rlDe0OOdyJ30VeZ6Z\ndU2xvIQw5vXpZjZO0i2sripXeMQK5qXsVt5Lis65HFGNq8+Ekt5MMxsXpx8nJMlvE9Xi+HNu0vqt\nk7ZvBcxOdQBPis653BA1bn02s2+AryVtFWftDXwKjAD6x3n9gafj+xHAcbEVugewIFHNroxXn51z\nOZK1Z59PBx6S1AD4EjieUMB7TNJA4Cugb1z3OeBAYAqwKK6bkidF51zuZOHZZzN7H6jouuPeFaxr\nwKlV2b8nRedc7njXYc45F8m7DnPV9OKoFzh7yJmUlZUx4IQTOefcVHccFL+pk7/gtJOOXTX99fRp\n/Pm8ixk4+HTuvePf3H/nbdQvKWGvfXtx/qVX5THS7Jr07778vHg5K1caK1YaPf86AoDBB2zD4F6d\nWLFyJS+8+zUXPTiBdUrqMXTQruzYvikrDc65523GfvJNnj9BNXjXYa6qysrKOOuMU3n2+dGUtmpF\nzx7d6N27D9t06pTv0GpN+45b8vyYcIdFWVkZO/+2Pfsf1If/jX2N0c+P5PnX36Fhw4bM+25umj0V\nnwMufZ7vf166anqPbX9D725t6P6Xp1i2YiXNNlwXgBP2CY2t3f/yX5ptuC7/vXA/ep43Akt5x11h\nEVCvXuGXFAs/wrXMO+PH0759B7Zo144GDRrQ98ijGPnM0+k3rCPefP1V2rTdglat2/DQvbdz8pln\n07BhQwCaNmueZuvid9L+23DDUx+ybMVKAL77aQkAW7dqwqsfzVk1b/6iZezUvmne4qwWZfAqAJ4U\nC8zs2bNo1Wr1vaalpa2YNWtWHiPKrWeeGk6fw44A4MupUxj/1pscst/uHHHwvnwwcUKeo8suM3jm\n4v1589o+q0qCHTfbkN22acFrVx/MqMsOWJX4Ppr+A727b079eqJN88bs2G5TSjddP5/hV4OQUr8K\nQdFVnyVtDQwjPKpzuJlNzXC7O4EbzexTSdOBrmY2r/YirR6roD5UKL8stW3ZsmW89MKznHvR5QCU\nrVjBTwt+5L+jXueD9yZw6ol/ZOy7k+rM97H3RSOZ8+Nimm24Ls/8rRefz5pP/fr1aNK4Ab87/xm6\ndmjKA0N+T6dTh3PfK1+wVauNePPaPnw1byHjPp9L2coiqjtHxVB9LrqkSOj94mkzuyR5psL/FJnZ\nyoo2MrMTcxFcTZWWtmLmzNXPr8+aNZOWLVvmMaLcGfPSKLbbvjPNmrcA4DctS9n/oEORROcu3ahX\nrx4/fD+PTZs2y3Ok2THnx8VAqA4/M34GXTs2Y/b3v/D0uBkATJgyj5VmNN1wXeb9tIS/3jt+1bav\nXHkQU+b8lJe4a6IY/qDVWtqW1DZ2AHmHpE8kvShpPUmdJb0dO3x8KqkzyDGSrpU0XtIXknavYJ8H\nAmcBJ0p6NekY/wYmAq0l/Sf2rvGJpMuSth0jKdWD5gWha7duTJkymenTprFs2TKGPzqMg3r3yXdY\nOTHiycc4OFadAfY74GDeGjsGgC+nTGb5smVssmmRXUerRKOGJTRet2TV+713aMmnX/3IM+/MYM/t\nQs9WHTbbkAYl9Zj30xLWa1CfRg3D+ntt35IVZcZnM+fnLf5qKZJrirVdUuwIHG1mJ0l6DPg/4FxC\nDxevSbocuISQ6ABKzKx7TH6XAPsk78zMnpN0G7DQzP4hqS2wFXC8mZ0CIOlCM/tBUn3gZUnbm9mH\ntfw5s6akpISbbhnKwQftT1lZGf0HnECnbbfNd1i1bvGiRbzx2itcdePQVfOO6Nefc8/4E/v13Il1\n1mnADUPvLIqSRiaab7Qew84ND2CU1BePjf2S0e/PYp2Setx2Sk/eufEPLF9RxklDxwLQbKP1GHHR\n/qw0Y/YPixj4z9fyGX61iMK5bphKbSfFafGRHIB3gfZAEzNLnNH7gOFJ6z+ZtG7bDI8xI3YemXBE\n7IOtBNgM6ARklBTjdoMAWm++eYaHz75eBxxIrwMOzNvx82G9Ro14f/KaDUoNGjTg5tvuyVNEtWv6\n3J/pcfZ/fzV/+YqVDPzn67+a/9V3C+l85hO5CK1WFcM1xdqOcGnS+zKgSYbrlxETtqR7JL0v6blK\ntvkl8UbSFsDZwN5mtj3wLLBupsGa2e1m1tXMujarI9etnCsk3vr8awuAHyXtbmZjgWOBlPUAM0vb\nq0WSDQlJcoGkFoTxGcZUM1bnXDYV0HXDVPLR+twfuE1SI1Z3+5MVZvaBpPeAT+K+38zWvp1zNSNU\nFNXnWkuKZjYd2C5p+h9Ji3tUsP6eSe/nUck1RTO7tLJjxHkDKtkuef8V7ts5V7sKpYqcSjHep+ic\nK1aFnxM9KTrnckTF0frsSdE5lzNefXbOuchv3nbOuWQC1Sv8pFj4FXznXJ2RjZu3JU2X9FF8qGNC\nnLeJpNGSJsefiT4VJOmfkqbE/ha6pNu/J0XnXM5k8YmW35tZZzNLdPJyHvCymXUEXo7TEB7g6Bhf\ng4D/pNuxJ0XnXM6onlK+auAQQl8KxJ+HJs2/34K3gSaSNku1I0+KzrmcSFdKjCXFprHrv8RrUAW7\nMuBFSe8mLW9hZnMA4s/E2BWlwNdJ286M8yrlDS3OuZzJoIo8L6lKXJndzGy2pObAaEmfpTpkBfNS\ndlnuJUXnXM5ko/psZrPjz7nAU0B34NtEtTj+TAz9OBNonbR5K2B2qv17UnTO5UxNG1okrS9pg8R7\nYD/gY2AEobMZ4s/EEJgjgONiK3QPYEGiml0Zrz4753JDWXmipQXwVNxPCfCwmb0g6R3gMUkDga+A\nvnH954ADgSnAIjLolcuTonMuJ0LXYTVLimb2JbBDBfO/B/auYL4Bp1blGJ4UnXM5UwRP+XlSdM7l\njj/77JxzkQT163tSdM65VYqgoOhJ0TmXO159ds65SKLGrc+54EnROZcj3smsc86toQhyoidF51yO\nePXZOedWE97Q4pxzayiCnOhJ0TmXO159dkWrxUbr5juEvJr70IB8h5B3GzwxMLs7zE4vObXOk6Jz\nLifCNcV8R5GeJ0XnXI7UvOuwXPCk6JzLGa8+O+dcgrz67JxzqwioV6/wh4XypOicyxkvKTrnXBK/\npuicc5FUHK3PhV/Bd87VGVLqV+b7UX1J70kaGae3kDRO0mRJj0pqEOc3jNNT4vK26fZdaVKUtGGq\nV+bhO+dcUE9K+aqCM4FJSdPXAjeZWUfgRyDxOM5A4Ecz6wDcFNdLHWOKZZ8AH8efn5Sb/rgq0Tvn\nXKLn7VSvzPajVsBBwJ1xWsBewONxlfuAQ+P7Q+I0cfneSnNhs9JrimbWOqMInXMuQxnkvaaSJiRN\n325mt5db52bgXGCDOL0pMN/MVsTpmUBpfF8KfA1gZiskLYjrz6ssgIwaWiQdBbQzs6tilm5hZu9m\nsq1zziVk0Po8z8y6pti+NzDXzN6VtGdidgWrWgbLKpS2oUXSUOD3wLFx1iLgtnTbOedcMpGVa4q7\nAX0kTQeGEarNNwNNJCUKea2A2fH9TKA1QFy+EfBDqgNk0vq8q5n9CVgCYGY/AA0yid4555LVU+pX\nOmZ2vpm1MrO2wFHAK2bWD3gVODyu1h94Or4fEaeJy18xs5qVFIHlkuoRi5ySNgVWZrCdc86tpjCa\nX6pXDfwVGCJpCuGa4V1x/l3ApnH+EOC8dDvK5JrircATQDNJlwFHAJdVJ2rn3NpLQP0s3rxtZmOA\nMfH9l0D3CtZZAvStyn7TJkUzu1/Su8A+cVZfM/NbcpxzVVYET/ll/JhffWA5oQrtT8E456qlGJ59\nzqT1+ULgEaAloVXnYUnn13Zgzrm6RQrV51SvQpBJSfGPwE5mtghA0pXAu8DVtRmYc67uKYy0l1om\nSXFGufVKgC9rJxznXF1WDNXnSpOipJsI1xAXAZ9IGhWn9wPeyE14zrm6QiqcKnIqqUqKiRbmT4Bn\nk+a/XXvhOOfqsiIoKKbsEOKuypY551x1FEP1OZPW5/aShkn6UNIXiVcugltbvTjqBbbfdiu23boD\n1193Tb7Dyak/nXgCm7dszk6dt8t3KDlz8qCBbNH6N3Tvsv2qeReefy5dtu9Ej66dOfqIw5g/f34e\nI8yOxM3bhd76nMk9h/cC9xA+0wHAY4QHsV0tKCsr46wzTuXpZ57nvQ8/ZfiwR5j06af5Ditnju0/\ngKdHvpDvMHKq37H9eWrEc2vM22uvfRg/8UPenvA+HTpuyQ3X140/jkrzKgSZJMVGZjYKwMymmtlF\nhF5zXC14Z/x42rfvwBbt2tGgQQP6HnkUI595Ov2GdUTP3fdgk002yXcYOdVz9z3YeOM1P/Pe++5H\nSUm4utWt+87MnjkzH6FllZTVnrdrTSZJcWnsqXaqpMGSDgaa13Jca63Zs2fRqtXq/n1LS1sxa9as\nPEbk8u2B++5h3/175TuMrMhGz9u1LZOk+GegMXAGoS+zk4ATajOoVCT1lTRJ0qtV3O5/8WdbSQX7\n7HZFvRoVw8VpVzuuv+YqSkpKOPLofvkOJSuyNXBVbcqkQ4hx8e3PrO5oNqsk1TezsgxXHwicYmZr\nJEVJJUndkf+Kme1akxhzpbS0FTNnfr1qetasmbRs2TKPEbl8eeiB+3j++WcZ+fzoOvGHURROFTmV\nVDdvP0WKbrvN7LBMDhCHFHwBGAfsCHwBHAd8CtxNuBl8qKR3CN2UNSPcMH6SmX1Wbl9/A3oCW0ga\nQbiH8iBgXWB9SX0InUtuDKwDXGRmT8dtF5pZ40xizqeu3boxZcpkpk+bRsvSUoY/Oox7H3g432G5\nHBv94gvcdMP1PD/6VRo1apTvcLIjDlxV6FKVFIdm8ThbAQPN7E1JdwOnxPlLzKwngKSXgcFmNlnS\nzsC/CV2Nr2Jml0vaCzjbzCZIGgDsAmxvZj/E7sb/YGY/SWoKvC1pRLqedhMkDQIGAbTefPMaf+jq\nKCkp4aZbhnLwQftTVlZG/wEn0GnbbfMSSz4c98ejGfvaGObNm0f7tq24+G+XMeCEgek3LGLHH3sM\nY8e+xvfz5rFV+8254KJLuPH6a1m6dCmHHLQ/EBpbbhn6nzxHWnPF0MVWqpu3X87icb42szfj+wcJ\n1ycBHgWQ1BjYFRieVE1omOG+R8chEiC06l8laQ9C7+ClQAvgm0x2FEcNux1gp526ZpRIa0OvAw6k\n1wEH5uvweXX/g4/kO4Scu6eCmkD/4+veHwJRHNfHM+1PsabKJ5jE9C/xZz3CEIWdk1eSVJ/QIw/A\nCDP7WwX7/iXpfT9C9XsnM1seB7dZtyaBO+eyp6QIioq5CnFzSbvE90dTrkMJM/sJmCapL4TBrSXt\nYGZlZtY5vipKiOVtRBj+cLmk3wNtsvkhnHPVF1qYa22MlqzJOClKyrQ6W5FJQH9JHwKbABVdHOkH\nDJT0AaEB5ZBqHOchoGscTLsf8Fma9Z1zOVTT0fxyIW31WVJ3wohYGxFKfDsAJ5rZ6VU4zkozG1xu\nXtvkCTObBqS9Q9XM9kx6fy/hMcTE9DxCw0tF2zWOP6cDa8+Dtc4ViGwMXCVpXeB1QptDCfC4mV0i\naQvC48ebABOBY81sWSzM3Q/sBHwPHBlzQKUyKSn+E+gdd4iZfYA/5uecq4Z6aV4ZWArsZWY7AJ2B\nXpJ6ANcCN5lZR+BHwv3MxJ8/mlkH4Ka4XtoY065jZjPKzcv0RmvMbLqZecnMOVfjJ1osWBgn14kv\nI9y+93icfx9waHx/SJwmLt9baS5eZpIUv45VaJNUX9JZhBuwnXMuY4met9N0HdZU0oSk16AK9lNf\n0vvAXGA0MJVw90riibaZhNvxiD+/BojLFwCbpoozk1tyTiZUoTcHvgVeivOcc65KMrikOM/MuqZa\nIT4S3FlSE+ApYJuKVos/KzpiynuQM3n2eS5wVLr1nHMuFUFWn302s/mSxgA9gCZJ/R+0AmbH1WYC\nrYGZ8Ym3jYAfKtpfQiatz3dQQWY1s18Va51zLpWa5kRJzYDlMSGuB+xDaDx5FTic0ALdn9AHAsCI\nOP1WXP5Kusd+M6k+v5T0fl3gD8Q6unPOZUxQv+Ylxc2A++LTbvWAx8xspKRPgWGSrgDeI9xGSPz5\ngKQphBJi2lpvJtXnR5OnJT1AuLjpnHMZC9Xnmu3DzD4k9LZVfv6XQPcK5i8B+lblGNV59nkL/PE5\n51w1FMpTK6lkck3xR1ZfU6xHKIKeV5tBOefqnmw80ZILKZNivMlxByAxSMjKTPsmdM65NRTQkAOp\npLx5OybAp2JvNWWeEJ1zNVFXRvMbL6lLrUfinKvTQvU59asQpBqjJXEjZE/gJElTCR26ilCI9ETp\nnKsCUa9ghryvXKpriuOBLqx+sNo556otDEeQ7yjSS5UUBWBmU3MUi3OuLhOUFHnrczNJQypbaGY3\n1kI8zrk6qi6UFOsDjam4lwnnnKuyQmlhTiVVUpxjZpfnLBLnXJ0moH7h58T01xSdcy4rVPzjPu+d\nsyicc2uFwk+JKZKimaXsiNE556oiVJ8LPy1Wp5cc55yrliLIiZ4UnXO5oqK/puicc1nj1WfnnCun\n8FOiJ0VXiW/mL8l3CHm1zb5n5zuEuqcO3JLjnHNZUyzV5wLpwcw5tzZQmlfa7aXWkl6VNEnSJ5LO\njPM3kTRa0uT4c+M4X5L+KWmKpA8z6RvWk6JzLmek1K8MrAD+YmbbAD2AUyV1Iowb9bKZdQReZvU4\nUgcAHeNrEPCfdAfwpOicy4lE9TnVKx0zm2NmE+P7n4FJQClwCHBfXO0+VvcDewhwvwVvA00kbZbq\nGJ4UnXM5orT/gKaSJiS9BlW6N6ktYQzocUALM5sDIXECzeNqpcDXSZvNjPMq5Q0tzrmcyaAwOM/M\nuqbfjxoDTwBnmdlPKVq1K1qQcgA+T4rOuZyQstP6LGkdQkJ8yMyejLO/lbSZmc2J1eO5cf5MoHXS\n5q2A2an279Vn51zO1LShJY5FfxcwqVzv/yOA/vF9f+DppPnHxVboHsCCRDW7Ml5SdM7ljGr+TMtu\nwLHAR5Lej/MuAK4BHpM0EPgK6BuXPQccCEwBFgHHpzuAJ0XnXE5k4+ZtM3uDym9p/FUfsGZmwKlV\nOYYnRedczhTBAy2eFJ1zuZOF6nOt86TonMsJkdkN2vnmSdE5lxuZP8qXV54UnXM5UwQ50ZOicy43\niqXrME+KzrncKfyc6EnROZc73vrsnHNJ6hV+TvSk6JzLIU+KzjkXhCEHCj8relJ0zuWGvPrsnHNr\n8qTonHMJ8uqzq54XR73A2UPOpKysjAEnnMg5556XfqMiNnXKF5x+4rGrpr+eMY0///Vieuy2Bxee\nczpLlyylpKSEy6+7mc5duuUx0uzaqPF6/OeSY+jUfjPMYPBlD7HPLttwwmG78t2PCwG4ZOgIRr3x\nKUcd0JWz+u+zatvfdmzJLkdfy4dfzMpX+FUmvPrsqqGsrIyzzjiVZ58fTWmrVvTs0Y3evfuwTadO\n+Q6t1rTvsCXPjRkHhM/f47ft2e+gPpw/5FTOPPtC9txnf14d/QLXXHYhw55+Mc/RZs8/zj2cF//3\nKceccxfrlNSn0boN2GeXbfjXg69y8wMvr7HusOcnMOz5CQBs26Elw28aVFQJcZUiSIo+HEGBeWf8\neNq378AW7drRoEED+h55FCO9TtHcAAASAklEQVSfeTr9hnXEm6+/Spu2W9CqdRuEWPjzTwD8/PMC\nWvwm5ciURWWD9delZ5f23PvUWwAsX1HGgoWLM9r2iF478dgL79ZmeLUmg9H88s5LigVm9uxZtGq1\nepyd0tJWjB8/Lo8R5dbIp4Zz8GFHAPC3K6+n/xEHc9Wl57Ny5Uoef+7VPEeXPVuUbsq8Hxdy+2V/\n5LdblvLepK85+7rHARh81B4c07s7Ez/9ivNufJL5P6+ZLA/frwt9/3x7PsKusWKoPhdlSVHSGZIm\nSXoow/VbSno8vt9T0sjajbD6Qu/pa0oxfGOdsmzZMl4a9SwH9jkMgAfvuZ2L/n4d//tgChf9/TrO\nO+vkPEeYPSUl9em8dWvuGD6WXY6+lkWLl3L2Cftyx/CxdDr4UnY+6hq+mfcT1ww5bI3tum3XhkVL\nlvPp1JRjLxUmZfAqAEWZFIFTgAPNrF9ihqRKS71mNtvMDs9JZDVUWtqKmTNXj909a9ZMWrZsmceI\ncmfMy6PYdvvONGveAoAnH32IXr0PBeCgQ/6PDyZOyGd4WTXr2x+ZNXc+73w8A4CnXnqfzlu3Zu4P\nP7NypWFm3P3km3Tdrs0a2/Xdfycee6F4v4diqD4XXVKUdBvQDhghaYGk2yW9CNwvqa2ksZImxteu\ncZu2kj7Oa+AZ6tqtG1OmTGb6tGksW7aM4Y8O46DeffIdVk488+Rj9PnDEaumm/9mM8b9bywA/xs7\nhrbtOuQrtKz79vufmfnNj3Rs0xyAPbtvxWdffsNvmm64ap1D9tphjRKhJA7bd0eGjyrW64mh+pzq\nVQiK7pqimQ2W1Av4PXAacDDQ08wWS2oE7GtmSyR1BB4Buma6b0mDgEEArTffPPvBZ6CkpISbbhnK\nwQftT1lZGf0HnECnbbfNSyy5tHjRIt547RWuvGHoqnlX33grl194DivKVtCwYUOuunFoij0UnyHX\nDueeqwbQoKQ+02fNY9AlD3LDuX3ZfqtWmBkz5vzA6Vc8smr9nl06MOvb+Uyf9X0eo66hGiY+SXcD\nvYG5ZrZdnLcJ8CjQFpgOHGFmP8Yxom8hDHG6CBhgZhPTHqOia1iFTtJ0QrI7jTCK4WVx/kbAUKAz\nUAZsaWaNJLUFRprZdpL2BM42s96pjrHTTl3tzXHFW02pqW/mL8l3CHm1zb5n5zuEvFvy/q3vmlnG\nhYp0ttuhiz3+whsp19mm5fopjylpD2AhcH9SUrwO+MHMrpF0HrCxmf1V0oHA6YSkuDNwi5ntnC7O\noqs+V+CXpPd/Br4FdiAkzQZ5icg5V6GaVp/N7HXgh3KzDwHui+/vAw5Nmn+/BW8DTSSlva+rLiTF\nZBsBc8xsJXAsUD/P8TjnkqVvfW4qaULSa1AGe21hZnMA4s/mcX4p8HXSejPjvJSK7ppiGv8GnpDU\nF3iVNUuRzrk8yrDrsHlZrLJXdLC01wuLMimaWdv49tJy8ycD2yfNOj/Onw5sF9+PAcbUboTOuV+p\nvRbmbyVtZmZzYvV4bpw/E2idtF4rYHa6ndW16rNzrpDVzs3bI4D+8X1/4Omk+ccp6AEsSFSzUynK\nkqJzrhjV/AZtSY8AexKuPc4ELgGuAR6TNBD4CugbV3+O0PI8hXBLzvGZHMOTonMuJ7LRdZiZHV3J\nor0rWNeAU6t6DE+KzrncKZCnVlLxpOicy5lCeb45FU+KzrmcKZTnm1PxpOicyw1BMfSC50nROZdD\nhZ8VPSk653LCB65yzrlyvPrsnHNJvPXZOeeSeEnROecieeuzc86tyavPzjmXxEuKzjmXxJOic86t\nUjhjO6fiSdE5lxPCS4rOObcGT4rOOZfEq8/OOZfg9yk659xqfk3ROefKKYbqsw9x6pzLmcSjfpW9\nMtuHekn6XNIUSedlO0ZPis65nKlpUpRUH7gVOADoBBwtqVM2Y/Sk6JzLGaX5l4HuwBQz+9LMlgHD\ngEOyGaNfU6zExInvzltvHc3IYwhNgXl5PH4hWNu/g3x//jbZ3Nl7E98d1aiBmqZZbV1JE5Kmbzez\n25OmS4Gvk6ZnAjtnK0bwpFgpM2uWz+NLmmBmXfMZQ76t7d9BXfv8ZtYrC7upqDhpWdjvKl59ds4V\nk5lA66TpVsDsbB7Ak6Jzrpi8A3SUtIWkBsBRwIhsHsCrz4Xr9vSr1Hlr+3ewtn/+XzGzFZJOA0YB\n9YG7zeyTbB5DZlmtjjvnXFHz6rNzziXxpOicc0k8KTpXwOITHEjF0JVC3eBJsYhJ2l3SHvmOI18k\ntZX0+3zHUVskbQ3cI2ljMzNPjLnhSbG4bQk8JqlnvgPJk+7AA5L2zXcgteQn4GfgH5KaeGLMDU+K\nRUhSN0nbmtldwHnAvZJ2z3dcuSKpo6SWZvYYcDZwo6T98h1XtkjqKuliM5sNXAcsBG7xxJgbnhSL\n0/bA/Fituhe4klDNWlsS4++B9pLWMbNhwPXADXUoMU4F7pS0g5nNAK4C5uOJMSf8PsUiFa833Qmc\nbWZvSzoeuBAYYGZv5De62iepBfAR0MPMvpR0HHAOMMTMRuc3upqLT2u8CHxlZsfFz3sB0Jhwzn/M\na4B1mJcUi0T5koGZfQaMBi6S1N3M7gH+DoyQtEs+YswlM/sWuB8YI6mtmd0PXAvcLmn//EZXdRWc\n32XA4cBGku6Mn/cqQucHV3pJsfZ4SbEISJLFEyVpb0Jp4WUzWyjpHGAv4G9m9o6kY4DxZjYljyFn\nXeI7kNQeWN/MPozzLwMGAbuY2XRJA4CpZjY2j+FWSbnzO4Dw+K2Z2V2SNgEeAGaa2Z8kNSf8v/02\nfxHXbZ4Ui4ikPwP/B0wGmgPXm9kYSUMIpYrTzGxiPmOsTZIOIjQ8vAO0Bw41s+8l/Q04F/itmU2L\n665KNMVC0pnAEYTLIM8A15jZlTExPg28Z2Zn5DPGtYF3CFHAypUg9gX2MbOecVyKXYH+cZUbJS2j\nDnfIKmknQkLsRbgV50HgCUlHmtnlktYB2gHTIBSz8hZsBmL1V2a2Mk63AvYFDgQGAm8Bf5bU2MzO\nl9SHUENwtcxLigWqXELcjdCPHMBuwACgD3AP0AH4q5m9ko84a0vimlmsMm9D+PxtgRaE1vZ9gYcI\nJca9zWxOYrtCT4gAMdktjO+PI/Qm/R7hj92FZrabpAOAZwnn9/r8Rbt28YaWAiRpg6SEuD9wA/BD\nvD1jK+A5M1sCvAZ8TmiFrTMklVgU/yA8DLQws4+APYEnzeynOL+McCkBKPwSIkAs9d0c3+9L6BPw\nIzObT/g/OS6u2ojQeJTV/gJdal59LjCS/gAcHm+x2Rn4D+E2m5/jKm8Bt0raEugGHGVm3+Un2uyT\n9FvCDen9YqPKecAFSQ1HnwG9JJ1LKC0OMLMP8hNt1UnaFDgDOEXS0cCJwDtmlrj0sRTYTNIDhPO7\nf/xj6HLEq88FRFJj4AlCa+N7wC/Afwktj73jOusAPYF9gPvN7PM8hZt1ktYDHiGUjEYQhrEcBEwH\njo8djG7N6s//oJmNzFO41SJpA2A4MJeQ9MYSLgn8I9FiLqkHsDGhFf2LfMW6tvKkWGAkDQZ6E55r\n3pbwn+NBYLqZDcpnbLVN0vrA1YQq8dbAEKAloWX9S+BGMyuL6yZu0SmKa4jJYin3EuBSM7te0hWE\nWtuzxXQrUV3l1xQLzwpCtfl5wnW0ucBxQAtJj+Q1slpmZr8AHxKqlJ+b2SRCSepZwgBFFyh2pZVI\nhMWWEKNHCWMVD5Q0kDC4+xLgyFhKdHnkSbHwjAH6Em6vGRyff/0GOBmoL2mzfAaXA18Ag4GtJZ0K\nrAReAF4hlBqzOhZxPpjZDDN7CTiGcM10P+AOwqh0X+YzNufV54KTVC3cHjiW0EPKSDN7V1L9RPWx\nrkr6/LsBVwDDCM94C9i4LjUqAUjagZDwTwcerevntxh4UsyTiq6FxV5flkvqAnwHbEAoIc4mXE9b\nmodQc0ZSQzNbKqkpoYS4BfBvQoPSrfmNrvbEFvfFde3RzGLlSTEPyt2Y3RZYmnTz8W6EqtQp8RG+\n7YFv4rXFOiOpRNgMWBSvJyKpHWFoz5vNbKRCB7rLzWxcqv05ly2eFHOsXEIcQnikawrwsZldKOlq\n4M1iu9WkOiQdCFwMjAc2M7MjJN0BTDOzq/IbnVtb+c3bOZaUEHcGuhBuv2lA6FZ/sZmdH5eXAGVF\n2rqaVnyW+QrC0xwHAHvHRSeb2Yq4Tr3Es8HO5Yq3PueYgh0IVeRlhE5EPyfci3ewpP8AmNmKupYQ\nE88zS2oELCf0/7gloRX24Lha18T6nhBdPnhSzIFEMoBQUoyPpf0D6Aj0iA0sXxFKTVtLap68TV0R\nryHuTbgNZXPCI4xXA7ub2TSFkQnPUuhl2rm88OpzDiRVmfsREuFcwlMqy4FLgcslvR0Tw76J6mNd\nI6kz4fG8Z8zsf5KuJPSDuKOkLQjd7V9o3oGqyyNvaMmReCPysYRne9sR+gQ8iNB/3mnAn83srfxF\nWDuSH8cD3iU8uTEAmBznn0boLmsF8LCZvVCMj+65usOTYi0p/2yupNuAu81sfFx+AdDOzE6MCfOZ\nWIWuc+JtNRsSOj64APinmf0rafkaHa46l09+TbEWlCvpdIw927Qi9AWYMJL4/ZvZrXUtISY1qvQg\n3IDdj9DJw3fAxbGECKy6zuoJ0RUEv6aYZeXuQzwNOAt4CvgAOEPSPDO7G/gt0FZSE2BBXasuxtJx\nd0Iv2SeZ2ThJHYCvCNXlCyQ1M7NL8hqoc+V4UsyypITYhzBo/f6EB/43BF4CrpC0I2FA9yMt9LZc\nV21EKB3vTehNegah2/2pwEVAad4ic64SXn2uBZJKgaFAiZlNBe4mJINJhLGKbwJ+Z2af5C/K2mdh\nUPrDgBMkHW1my4H5hBvWfzCzN+rirUeuuHlDSy2RdBghMQ4xs2GS6hFaXTsA19XxEuIaJB1MGGTq\neWAR8MTa8BijK06eFGuRwjjFVwNXJSXG9W31eCtrjXg54VLCEAI3JkqIde1aqit+fk2xFpnZs5JW\nArdLWmFmjwNrXUIEMLMRkpYAd0uabmZP5jsm5yriJcUcUBjGcqqZrfW9Kvt34QqdJ0XnnEvirc/O\nOZfEk6JzziXxpOicc0k8KTrnXBJPis45l8STogNAUpmk9yV9LGl4HDKguvvaU9LI+L6PpPNSrNtE\n0inVOMalks7OdH65de6VdHgVjtVW0sdVjdEVJ0+KLmGxmXU2s+0IY8cMTl4Yx5ap8u+LmY0ws2tS\nrNIEqHJSdK62eFJ0FRkLdIglpEmS/g1MBFpL2k/SW5ImxhJlYwBJvSR9JukNQicQxPkDJA2N71tI\nekrSB/G1K3AN0D6WUq+P650j6R1JH0q6LGlfF0r6XNJLwFbpPoSkk+J+PpD0RLnS7z6Sxkr6QlLv\nuH59SdcnHftPNf0iXfHxpOjWoDC06gHAR3HWVsD9ZrYj8Auhy699zKwLMAEYImldwuiEBwO7A7+p\nZPf/BF4zsx0Iw7t+QhjEamospZ4jaT/CODbdgc7ATpL2UBgS9ShgR0LS7ZbBx3nSzLrF400ijLGd\n0Bb4HWFIiNviZxhI6NuyW9z/SXHsGLcW8WefXcJ6kt6P78cCdwEtgRlm9nac3wPoBLwZ+3NoALxF\n6FF7mplNBpD0IDCogmPsBRwHYGZlwAJJG5dbZ7/4ei9ONyYkyQ2Ap8xsUTzGiAw+03aSriBU0RsD\no5KWPRZ7+54s6cv4GfYDtk+63rhRPPYXGRzL1RGeFF3CYjPrnDwjJr5fkmcBo83s6HLrdQay9byo\ngKvN7P+VO8ZZ1TjGvcChZvaBpAGsORxE+X1ZPPbpZpacPJHUtorHdUXMq8+uKt4GdovDCiCpkaQt\ngc+ALSS1j+sdXcn2LwMnx23rS9qQ0GvQBknrjCJ0Spu4VlkqqTnwOvAHSetJ2oBQVU9nA2COwhg5\n/cot6yupXoy5HfB5PPbJcX0kbSlp/QyO4+oQLym6jJnZd7HE9YikhnH2RWb2haRBwLOS5gFvANtV\nsIszCd2oDQTKgJPN7C1Jb8ZbXp6P1xW3Ad6KJdWFwB/NbKKkR4H3CcMajM0g5ItZPQzCR6yZfD8H\nXiOMMDjYzJZIupNwrXFi7O/xO+DQzL4dV1d4LznOOZfEq8/OOZfEk6JzziXxpOicc0k8KTrnXBJP\nis45l8STonPOJfGk6JxzSf4/Yiwq+/Nuf04AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ab2a35b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ab2a35be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "neigh.fit(final_X_train, final_y_train)\n",
    "preds = neigh.predict(final_X_test)\n",
    "print(\"Accuracy score %.2f\"%(accuracy_score(preds, final_y_test)))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(final_y_test, preds)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"non-frail\", \"pre-frail\", \"frail\"],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"non-frail\", \"pre-frail\", \"frail\"], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(labels, n_class = 6):\n",
    "    \"\"\" One-hot encoding \"\"\"\n",
    "    expansion = np.eye(n_class)\n",
    "    y = []\n",
    "    for i in labels:\n",
    "        y.append(expansion[int(i)])\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras.backend as K\n",
    "#from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "class BalancedAccuracy(Callback):\n",
    "    def __init__(self, train_data, validation_data):\n",
    "        super(BalancedAccuracy, self).__init__()\n",
    "        self.acas = []\n",
    "        self.validation_data = validation_data\n",
    "        self.train_data = train_data\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        X_val = self.validation_data[0]\n",
    "        y_val = self.validation_data[1]\n",
    "\n",
    "        X_train = self.train_data[0]\n",
    "        y_train = self.train_data[1]\n",
    "\n",
    "        y_val_pred = self.model.predict(X_val)\n",
    "        y_train_pred = self.model.predict(X_train)\n",
    "\n",
    "        val_score = self.eval_avg_class_acc(y_val, y_val_pred)\n",
    "        \n",
    "        print(\"\\nBalanced Accuracy - val: %.3f\"%(val_score))        \n",
    "        \n",
    "    def eval_avg_class_acc(self, y_true, y_pred):\n",
    "\n",
    "        # decode one-hot to single labels\n",
    "        y_pred = y_pred.round()\n",
    "        y_pred = [ np.argmax(pred, axis = 0) for pred in y_pred ]\n",
    "        y_true = [ np.argmax(label, axis = 0) for label in y_true ]\n",
    "\n",
    "        cf = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        class0_acc = float(cf[0][0]) / (float(cf[0][0]) + float(cf[0][1]) + float(cf[0][2]))\n",
    "        class1_acc = float(cf[1][1]) / (float(cf[1][1]) + float(cf[1][0]) + float(cf[1][2]))\n",
    "        class2_acc = float(cf[2][2]) / (float(cf[2][2]) + float(cf[2][0]) + float(cf[2][1]))\n",
    "        balanced_acc = float((class0_acc + class1_acc + class2_acc) / 3)\n",
    "\n",
    "        return balanced_acc\n",
    "\n",
    "def weighted_categorical_crossentropy(y_true, y_pred, weights):\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    # scale predictions so that the class probas of each sample sum to 1\n",
    "    y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # calc\n",
    "    loss = y_true * K.log(y_pred) * weights\n",
    "    loss = -K.sum(loss, -1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Weighted loss function to tackle class imbalance in the dataset\n",
    "\n",
    "weights = np.array([float(len(final_y_train)) / float(list(final_y_train).count(0)), float(len(final_y_train)) / float(list(final_y_train).count(1)), float(len(final_y_train)) / float(list(final_y_train).count(2))])\n",
    "w_cat_crossentropy = partial(weighted_categorical_crossentropy, weights = weights)\n",
    "w_cat_crossentropy.__name__ = 'weighted_categorical_crossentropy'\n",
    "        \n",
    "balanced_accuracy = BalancedAccuracy(train_data = (final_X_train, final_y_train), validation_data = (final_X_test, final_y_test))\n",
    "CALLBACKS = [balanced_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16556 samples, validate on 1726 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.7708 - acc: 0.5445 - val_loss: 7.9268 - val_acc: 0.4681\n",
      "\n",
      "Balanced Accuracy - val: 0.474\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.1702 - acc: 0.6615 - val_loss: 5.8273 - val_acc: 0.5174\n",
      "\n",
      "Balanced Accuracy - val: 0.471\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.9770 - acc: 0.6963 - val_loss: 7.4905 - val_acc: 0.4282\n",
      "\n",
      "Balanced Accuracy - val: 0.520\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.8312 - acc: 0.7185 - val_loss: 11.3605 - val_acc: 0.3053\n",
      "\n",
      "Balanced Accuracy - val: 0.473\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.7212 - acc: 0.7342 - val_loss: 6.7282 - val_acc: 0.5632\n",
      "\n",
      "Balanced Accuracy - val: 0.531\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.6013 - acc: 0.7515 - val_loss: 9.2223 - val_acc: 0.4519\n",
      "\n",
      "Balanced Accuracy - val: 0.536\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.4846 - acc: 0.7711 - val_loss: 9.6949 - val_acc: 0.5098\n",
      "\n",
      "Balanced Accuracy - val: 0.534\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.4414 - acc: 0.7798 - val_loss: 8.9986 - val_acc: 0.4467\n",
      "\n",
      "Balanced Accuracy - val: 0.511\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.3594 - acc: 0.7921 - val_loss: 6.0634 - val_acc: 0.5973\n",
      "\n",
      "Balanced Accuracy - val: 0.553\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.3038 - acc: 0.7981 - val_loss: 7.3062 - val_acc: 0.5678\n",
      "\n",
      "Balanced Accuracy - val: 0.555\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.2556 - acc: 0.8041 - val_loss: 12.8232 - val_acc: 0.4340\n",
      "\n",
      "Balanced Accuracy - val: 0.511\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.1709 - acc: 0.8180 - val_loss: 13.5313 - val_acc: 0.5093\n",
      "\n",
      "Balanced Accuracy - val: 0.565\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.1643 - acc: 0.8162 - val_loss: 10.6572 - val_acc: 0.4762\n",
      "\n",
      "Balanced Accuracy - val: 0.538\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.0779 - acc: 0.8328 - val_loss: 10.4154 - val_acc: 0.5423\n",
      "\n",
      "Balanced Accuracy - val: 0.548\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.0300 - acc: 0.8354 - val_loss: 14.6262 - val_acc: 0.3835\n",
      "\n",
      "Balanced Accuracy - val: 0.513\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.0102 - acc: 0.8443 - val_loss: 10.2925 - val_acc: 0.5701\n",
      "\n",
      "Balanced Accuracy - val: 0.600\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.9657 - acc: 0.8493 - val_loss: 13.3628 - val_acc: 0.4421\n",
      "\n",
      "Balanced Accuracy - val: 0.530\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.9314 - acc: 0.8549 - val_loss: 7.8923 - val_acc: 0.5516\n",
      "\n",
      "Balanced Accuracy - val: 0.540\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.9373 - acc: 0.8508 - val_loss: 18.4318 - val_acc: 0.4044\n",
      "\n",
      "Balanced Accuracy - val: 0.479\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.8996 - acc: 0.8571 - val_loss: 11.1451 - val_acc: 0.5290\n",
      "\n",
      "Balanced Accuracy - val: 0.584\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.8370 - acc: 0.8684 - val_loss: 11.2987 - val_acc: 0.5742\n",
      "\n",
      "Balanced Accuracy - val: 0.592\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.8430 - acc: 0.8665 - val_loss: 14.2160 - val_acc: 0.5261\n",
      "\n",
      "Balanced Accuracy - val: 0.547\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.8146 - acc: 0.8725 - val_loss: 14.0292 - val_acc: 0.4791\n",
      "\n",
      "Balanced Accuracy - val: 0.514\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.7974 - acc: 0.8750 - val_loss: 10.7455 - val_acc: 0.5765\n",
      "\n",
      "Balanced Accuracy - val: 0.588\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.7410 - acc: 0.8840 - val_loss: 15.0609 - val_acc: 0.5110\n",
      "\n",
      "Balanced Accuracy - val: 0.549\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.7237 - acc: 0.8834 - val_loss: 10.1824 - val_acc: 0.5637\n",
      "\n",
      "Balanced Accuracy - val: 0.575\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6816 - acc: 0.8889 - val_loss: 19.3423 - val_acc: 0.4751\n",
      "\n",
      "Balanced Accuracy - val: 0.508\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6328 - acc: 0.8995 - val_loss: 14.5471 - val_acc: 0.4728\n",
      "\n",
      "Balanced Accuracy - val: 0.540\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.6875 - acc: 0.8899 - val_loss: 15.2892 - val_acc: 0.5533\n",
      "\n",
      "Balanced Accuracy - val: 0.569\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.6579 - acc: 0.8936 - val_loss: 14.5557 - val_acc: 0.5388\n",
      "\n",
      "Balanced Accuracy - val: 0.562\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.6465 - acc: 0.8964 - val_loss: 15.5921 - val_acc: 0.5336\n",
      "\n",
      "Balanced Accuracy - val: 0.545\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.6078 - acc: 0.9030 - val_loss: 17.3447 - val_acc: 0.4861\n",
      "\n",
      "Balanced Accuracy - val: 0.542\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.5752 - acc: 0.9061 - val_loss: 19.4248 - val_acc: 0.4583\n",
      "\n",
      "Balanced Accuracy - val: 0.515\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.5996 - acc: 0.9038 - val_loss: 26.1928 - val_acc: 0.4548\n",
      "\n",
      "Balanced Accuracy - val: 0.514\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.5949 - acc: 0.9049 - val_loss: 13.8426 - val_acc: 0.5301\n",
      "\n",
      "Balanced Accuracy - val: 0.558\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.5960 - acc: 0.9038 - val_loss: 16.5453 - val_acc: 0.5058\n",
      "\n",
      "Balanced Accuracy - val: 0.529\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5926 - acc: 0.9038 - val_loss: 24.4076 - val_acc: 0.4085\n",
      "\n",
      "Balanced Accuracy - val: 0.535\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.5766 - acc: 0.9031 - val_loss: 15.2920 - val_acc: 0.5429\n",
      "\n",
      "Balanced Accuracy - val: 0.547\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.5286 - acc: 0.9175 - val_loss: 13.7977 - val_acc: 0.5921\n",
      "\n",
      "Balanced Accuracy - val: 0.558\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.5675 - acc: 0.9058 - val_loss: 17.5457 - val_acc: 0.5209\n",
      "\n",
      "Balanced Accuracy - val: 0.571\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.5298 - acc: 0.9156 - val_loss: 14.5416 - val_acc: 0.5788\n",
      "\n",
      "Balanced Accuracy - val: 0.565\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4808 - acc: 0.9206 - val_loss: 16.3941 - val_acc: 0.5365\n",
      "\n",
      "Balanced Accuracy - val: 0.546\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4680 - acc: 0.9229 - val_loss: 13.2139 - val_acc: 0.6141\n",
      "\n",
      "Balanced Accuracy - val: 0.600\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4881 - acc: 0.9233 - val_loss: 18.1853 - val_acc: 0.4988\n",
      "\n",
      "Balanced Accuracy - val: 0.535\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4730 - acc: 0.9262 - val_loss: 16.2284 - val_acc: 0.5342\n",
      "\n",
      "Balanced Accuracy - val: 0.562\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4359 - acc: 0.9308 - val_loss: 21.5579 - val_acc: 0.5035\n",
      "\n",
      "Balanced Accuracy - val: 0.566\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4219 - acc: 0.9322 - val_loss: 20.5291 - val_acc: 0.4247\n",
      "\n",
      "Balanced Accuracy - val: 0.531\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4403 - acc: 0.9301 - val_loss: 17.0400 - val_acc: 0.5516\n",
      "\n",
      "Balanced Accuracy - val: 0.558\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4988 - acc: 0.9187 - val_loss: 17.3098 - val_acc: 0.5440\n",
      "\n",
      "Balanced Accuracy - val: 0.565\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4721 - acc: 0.9242 - val_loss: 24.1960 - val_acc: 0.4565\n",
      "\n",
      "Balanced Accuracy - val: 0.537\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4251 - acc: 0.9301 - val_loss: 19.9269 - val_acc: 0.5562\n",
      "\n",
      "Balanced Accuracy - val: 0.562\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4208 - acc: 0.9318 - val_loss: 18.8506 - val_acc: 0.5348\n",
      "\n",
      "Balanced Accuracy - val: 0.590\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3882 - acc: 0.9375 - val_loss: 18.3427 - val_acc: 0.5487\n",
      "\n",
      "Balanced Accuracy - val: 0.582\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3679 - acc: 0.9417 - val_loss: 22.2925 - val_acc: 0.4965\n",
      "\n",
      "Balanced Accuracy - val: 0.538\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3848 - acc: 0.9385 - val_loss: 16.5132 - val_acc: 0.5886\n",
      "\n",
      "Balanced Accuracy - val: 0.591\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3833 - acc: 0.9387 - val_loss: 18.2765 - val_acc: 0.5707\n",
      "\n",
      "Balanced Accuracy - val: 0.606\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4136 - acc: 0.9344 - val_loss: 30.7221 - val_acc: 0.4032\n",
      "\n",
      "Balanced Accuracy - val: 0.512\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4125 - acc: 0.9366 - val_loss: 26.5449 - val_acc: 0.4948\n",
      "\n",
      "Balanced Accuracy - val: 0.567\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3951 - acc: 0.9378 - val_loss: 18.6604 - val_acc: 0.5301\n",
      "\n",
      "Balanced Accuracy - val: 0.577\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3898 - acc: 0.9363 - val_loss: 29.0980 - val_acc: 0.4519\n",
      "\n",
      "Balanced Accuracy - val: 0.542\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3785 - acc: 0.9388 - val_loss: 16.6300 - val_acc: 0.5411\n",
      "\n",
      "Balanced Accuracy - val: 0.552\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4775 - acc: 0.9273 - val_loss: 21.0132 - val_acc: 0.5174\n",
      "\n",
      "Balanced Accuracy - val: 0.568\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.5368 - acc: 0.9179 - val_loss: 30.2842 - val_acc: 0.4200\n",
      "\n",
      "Balanced Accuracy - val: 0.526\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4924 - acc: 0.9230 - val_loss: 22.0006 - val_acc: 0.5492\n",
      "\n",
      "Balanced Accuracy - val: 0.580\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4964 - acc: 0.9250 - val_loss: 21.9010 - val_acc: 0.5301\n",
      "\n",
      "Balanced Accuracy - val: 0.578\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3920 - acc: 0.9386 - val_loss: 23.1590 - val_acc: 0.5064\n",
      "\n",
      "Balanced Accuracy - val: 0.545\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3773 - acc: 0.9372 - val_loss: 25.1045 - val_acc: 0.4195\n",
      "\n",
      "Balanced Accuracy - val: 0.533\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3083 - acc: 0.9526 - val_loss: 20.3090 - val_acc: 0.5556\n",
      "\n",
      "Balanced Accuracy - val: 0.584\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.3868 - acc: 0.9363 - val_loss: 22.9217 - val_acc: 0.4699\n",
      "\n",
      "Balanced Accuracy - val: 0.550\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.3833 - acc: 0.9392 - val_loss: 21.4122 - val_acc: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Accuracy - val: 0.601\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3314 - acc: 0.9473 - val_loss: 19.5267 - val_acc: 0.5510\n",
      "\n",
      "Balanced Accuracy - val: 0.579\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.2938 - acc: 0.9557 - val_loss: 28.4024 - val_acc: 0.4438\n",
      "\n",
      "Balanced Accuracy - val: 0.539\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3003 - acc: 0.9525 - val_loss: 25.5210 - val_acc: 0.3957\n",
      "\n",
      "Balanced Accuracy - val: 0.534\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3211 - acc: 0.9484 - val_loss: 36.1934 - val_acc: 0.4073\n",
      "\n",
      "Balanced Accuracy - val: 0.538\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.2812 - acc: 0.9565 - val_loss: 28.7822 - val_acc: 0.4513\n",
      "\n",
      "Balanced Accuracy - val: 0.542\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.2719 - acc: 0.9569 - val_loss: 27.1202 - val_acc: 0.4838\n",
      "\n",
      "Balanced Accuracy - val: 0.547\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.2491 - acc: 0.9608 - val_loss: 32.4718 - val_acc: 0.4287\n",
      "\n",
      "Balanced Accuracy - val: 0.535\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.2942 - acc: 0.9509 - val_loss: 23.4613 - val_acc: 0.5168\n",
      "\n",
      "Balanced Accuracy - val: 0.569\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.2689 - acc: 0.9572 - val_loss: 29.9921 - val_acc: 0.4705\n",
      "\n",
      "Balanced Accuracy - val: 0.540\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.2494 - acc: 0.9615 - val_loss: 30.2803 - val_acc: 0.4699\n",
      "\n",
      "Balanced Accuracy - val: 0.543\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.2288 - acc: 0.9638 - val_loss: 30.7778 - val_acc: 0.4061\n",
      "\n",
      "Balanced Accuracy - val: 0.514\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.2794 - acc: 0.9578 - val_loss: 29.2520 - val_acc: 0.5070\n",
      "\n",
      "Balanced Accuracy - val: 0.573\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.2712 - acc: 0.9577 - val_loss: 22.8468 - val_acc: 0.5197\n",
      "\n",
      "Balanced Accuracy - val: 0.566\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4411 - acc: 0.9376 - val_loss: 23.6615 - val_acc: 0.5475\n",
      "\n",
      "Balanced Accuracy - val: 0.574\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4242 - acc: 0.9366 - val_loss: 24.1146 - val_acc: 0.5070\n",
      "\n",
      "Balanced Accuracy - val: 0.585\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3760 - acc: 0.9372 - val_loss: 22.2924 - val_acc: 0.5139\n",
      "\n",
      "Balanced Accuracy - val: 0.559\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3095 - acc: 0.9507 - val_loss: 30.9151 - val_acc: 0.4455\n",
      "\n",
      "Balanced Accuracy - val: 0.543\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.2850 - acc: 0.9548 - val_loss: 29.5257 - val_acc: 0.4652\n",
      "\n",
      "Balanced Accuracy - val: 0.542\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3300 - acc: 0.9470 - val_loss: 25.7686 - val_acc: 0.4739\n",
      "\n",
      "Balanced Accuracy - val: 0.551\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.2464 - acc: 0.9616 - val_loss: 30.7152 - val_acc: 0.4305\n",
      "\n",
      "Balanced Accuracy - val: 0.554\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.2150 - acc: 0.9665 - val_loss: 29.6169 - val_acc: 0.4548\n",
      "\n",
      "Balanced Accuracy - val: 0.541\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.2538 - acc: 0.9618 - val_loss: 27.1603 - val_acc: 0.4849\n",
      "\n",
      "Balanced Accuracy - val: 0.543\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.2336 - acc: 0.9655 - val_loss: 28.5325 - val_acc: 0.4988\n",
      "\n",
      "Balanced Accuracy - val: 0.561\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.2161 - acc: 0.9674 - val_loss: 33.6322 - val_acc: 0.4681\n",
      "\n",
      "Balanced Accuracy - val: 0.559\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1958 - acc: 0.9710 - val_loss: 26.4978 - val_acc: 0.4670\n",
      "\n",
      "Balanced Accuracy - val: 0.560\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.2024 - acc: 0.9690 - val_loss: 26.5110 - val_acc: 0.5162\n",
      "\n",
      "Balanced Accuracy - val: 0.576\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1795 - acc: 0.9743 - val_loss: 27.9895 - val_acc: 0.5023\n",
      "\n",
      "Balanced Accuracy - val: 0.561\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.2031 - acc: 0.9702 - val_loss: 26.2092 - val_acc: 0.4959\n",
      "\n",
      "Balanced Accuracy - val: 0.562\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.2176 - acc: 0.9672 - val_loss: 28.7410 - val_acc: 0.4647\n",
      "\n",
      "Balanced Accuracy - val: 0.537\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1984 - acc: 0.9701 - val_loss: 26.5657 - val_acc: 0.5116\n",
      "\n",
      "Balanced Accuracy - val: 0.566\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalAveragePooling1D, LSTM\n",
    "from keras.layers import Activation, BatchNormalization, Reshape\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, kernel_initializer=\"random_uniform\", input_shape = (96,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "\n",
    "adam = Adam(lr = 0.01)\n",
    "y_train_one_hot = one_hot(final_y_train, 3)\n",
    "y_test_one_hot = one_hot(final_y_test, 3)\n",
    "\n",
    "model.compile(loss=w_cat_crossentropy, optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(final_X_train, y_train_one_hot, epochs=100, batch_size=512, validation_data=(final_X_test, y_test_one_hot), \n",
    "          verbose=2, shuffle=True, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970101473728\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c65deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VFX6x/HPNwlBeq8JvQiKFcWG\nHTvquvaOZe29rK64dtfu+nPFde1ixS4gii4uKipKExXpTTqhKp0kz++PexMmYZIMZDIzSZ43r3kx\n994z5z53ypNzbjlXZoZzzlVnackOwDnnks0ToXOu2vNE6Jyr9jwROueqPU+EzrlqzxOhc67a80SY\nQJLukvRa+LytpDWS0uO8jjmS+sSzzhjWebmkJeH2NClHPWskdYxnbMkiaZKkQ5Idh4tNlUqEYRJY\nIqlOxLyLJY1MYlhRmdlvZlbXzPKSHUt5SKoBPA4cGW7P8u2tK3z9rPhFF3+SXpZ0X1nlzGxnMxsZ\n53WfHf6xWCNpvaT8iOk15ai3m6TceMYaUfdoSedURN3xVKUSYSgDuLa8lShQFd+feGsB7ABMSnYg\nqUBSRkXVbWavh38s6gLHAAsLpsN5bjtVxR/6I8BNkhpGWyhpf0ljJK0O/98/YtlISfdL+gZYB3QM\n590n6dvwL+8QSU0kvS7p97CO9hF1/J+keeGycZIOLCGO9pJMUoak/SL/skvaIGlOWC5N0q2SZkpa\nLultSY0j6jlX0txwWf/S3hhJtSQ9FpZfLWmUpFrhshPC7tyqcJu7R7xujqSbJP0Uvm6QpB0kdQWm\nhsVWSfoicruKva8Xh887S/oyrGeZpEER5UxS5/B5A0kDJeWE8d5e8IdJUr8w9kclrZQ0W9IxpWz3\nHEk3h/GvlfSCpBaSPpH0h6T/SmoUUf4dSYvDGL+StHM4/xLgbOCvBd+FiPpvkfQTsDb8TAt3UUga\nJumxiPoHSXqxtM9qe0lqI+mj8L2dJemyiGUHSJoQfjcXS3ogXPQVkB7x/dsjSr0lvRZJB0r6Pvzu\njJd0QDj/MWBv4Pmw3seK15syzKzKPIA5QB/gfeC+cN7FwMjweWNgJXAuQcvxzHC6Sbh8JPAbsHO4\nvEY4bwbQCWgA/ApMC9eTAQwEXoqI4RygSbjsRmAxsEO47C7gtfB5e8CAjGLbULDOB8Lp64DRQDZQ\nE/gP8Ga4bCdgDXBQuOxxIBfoU8L7MyCsOwtIB/YPX9cVWAscEa7/r+E2Z0a8rz8ArcP3cDJwWbTt\niLZd4TovDp+/CfQn+CO8A9A7opwBncPnA4GPgHphndOAi8Jl/YDNwF/C7bgcWAiolO/FaILWaxaw\nFBgP7BFu/xfAnRHlLwzXWxN4AvgxYtnLhN+tYvX/CLQBakV+F8PnLcN1HkaQSGcB9cr5XT8EmF9s\nXjrwM3ALkBl+rr8BB4fLJwCnhs/rAfuEz7sBuWWsr6TXtgeWE/we0oBjgRygUbh8NHBOsnNDme9n\nsgOI68ZsSYQ9gNVAM4omwnOBH4q95jugX/h8JHBPseUjgf4R048Bn0RMHx/5Q4kS00pgt/D5XZSd\nCP8NfAykhdOTgcMjlrciSAIZwB3AWxHL6gCbiJIIwy/p+oJYii37O/B2sbILgEMi3tdzIpY/DDwT\nbTuibRdFE+FA4FkgO0ocBnQm+EFvBHaKWHZpxOfYD5gRsax2+NqWpXwvzo6Yfg/4d8T01cCHJby2\nYVh3g3D6ZaInwgujfRcjpv8MzAOWEZH8y/FdP4StE+HBwPRi8+4u2FaCP2b9Cf/wR5SJJRGW9No7\ngeeKzfsSOD18XikSYVXsGmNmvwBDgVuLLWoNzC02by5BK6HAvChVLol4vj7KdOH+GUk3SpocdqtW\nEbQim8YSt6RLCb7gZ5lZfji7HfBB2O1YRZAY8whaN60j4zWztQR/naNpStACmxllWZH3JVz3PIq+\nL4sjnq8jYpu30V8BAT+EXfELS4g1k6KfVfHPqTAeM1sXPi0tppg+Q0npkh4Md0X8TpDQCmIqTbTv\nTaShBAl+qpmNKqmQiu4iaVtGncW1A9oXfFfC78sNBC1SgPOBXYFpYVf2qG2ou6TXtgPOKbbOvQi+\nU5VGhe3YTQF3EnR/IvdLLCT44CK1BT6NmN7u4XgU7A+8BTgcmGRm+ZJWEvzwY3ntvQSthdURi+YR\ntDa+ifKaRUDkvrzaBN3yaJYBGwi6+BOLLVsI7BJRjwi6eQvKijuKteH/tYHfw+cFP0TMbDFBlxZJ\nvYH/SvrKzGYUi3UzwWf1aziv7XbGs63OAk4k6FnMIfhDFvkZlvT9KOt7cz/BH7EOks40szejVlK+\ngx7zgClmtku0hWY2GThdwSlbZwDvh/tGy/zOl/LaecDzZnZ1SS/dju1IuCrZIgQIf1iDgGsiZg8D\nuko6K9yhfTrBfrahcVptPYJ9dDlAhqQ7gPplvUhSmzDW88xsWrHFzwD3S2oXlm0m6cRw2btAX0m9\nJWUC91DCZxq28l4EHpfUOmz57CepJvA2cJykwxWcDnMjQdf0223a+mA9OQQJ65xwHRcSJN+CbT1V\nUnY4uZLgh5JXrI68MKb7JdULt/0G4LVtjWc71CPY9uUEyfwfxZYvAbbpXEdJBwEXAOeFj39Jyir9\nVdtlVLi+6xQczMqQtKukPcP550lqEr6/qwne+3yC/ZfppbVAS3ntK8Cp4XcnXcEBucMlFfzx2+b3\nKxmqbCIM3UOw3wwAC85x60vwQ19O0E3ra2bL4rS+4cAnBDv25xK0wMrqMkHQgmwJvBvRLSo4HeX/\ngMHAZ5L+INjnsk+4PZOAK4E3gEUEiWV+Keu5iWBn+hhgBfAQwb7IqQQHef5F0Bo7HjjezDbFuN3F\n/QW4meA93pmiCXVv4HsF570NBq41s9lR6riaoHU5i+AH/gZBIq9oAwk+uwUErdHRxZa/AOwUdgM/\nLKsySfXDOq8yswVht/gF4KWw5R03ZraZ4GDF/uE25BDscy5oZfYFpobfoweA08ws18xWEuz3HRdu\n1+5Rqi/ptbOAkwn2RS4L13stW3LLP4HzFBzdfzie2xtPCndoOudctVXVW4TOOVcmT4TOuWrPE6Fz\nrtrzROicq/aq8nmE5aKMWqbMeskOI2my27ZIdghJ1axOzWSHkHTjx49bZmbN4lVfev12ZrnrSy1j\n63OGm9nR8VpnrDwRlkCZ9ai542nJDiNpbnzyxmSHkFSX7tch2SEkXa0aKn4VVrlY7voyf1MbfhwQ\n01VY8eaJ0DmXGBKkxXUc4rjxROicS5wUHeLTE6FzLnHiezFN3HgidM4liHeNnXPVnfCusXOuupN3\njZ1zzrvGzrlqTt41ds5Vc8K7xs656k6QlpopJzWjcs5VTWneInTOVWcpfPpMakblnKuCwhOqS3vE\nUot0tKSpkmZIKn7L3oIyp0n6Nbxl7Btl1ektQudc4pTzYEl4O9EBwBEENyobI2mwmf0aUaYL8Dfg\nADNbKal5WfV6i9A5lzhKK/1Rtl7ADDObFd5l8S2C+1BH+gswILw7H2a2tKxKPRE65xJDcekaZ1H0\nFrnzw3mRuhLcv/wbSaMllTnQq3eNnXOJU3bXuKmksRHTz5rZs5E1RHlN8XsSZwBdgEOAbOBrST3M\nbFVJK/VE6JxLkJiuLFlmZnuVsnw+0CZiOhtYGKXM6PCG97MlTSVIjGNKqtS7xs65xBDx6BqPAbpI\n6iApEzgDGFyszIfAoQCSmhJ0lWeVVqm3CJ1zCVL+a43NLFfSVcBwIB140cwmSboHGGtmg8NlR0r6\nFcgDbjaz5aXV64nQOZc4cbjW2MyGAcOKzbsj4rkBN4SPmHgidM4ljg/D5Zyr1uTDcLkIR+zfnUdv\nPoX0tDRe/vBbHn3p863KnHzEHvS/7FjM4OdpC+h328sArBn7JL/MCA6SzVu8klOv+08iQ4+Lyd9/\nyftP3oPl57PvcafR55zLiyz/5qPXGfX+qyg9nZq1anP6zf+gZfsuAHz+2tN8//E7KC2NP197J917\nHZSMTSiXz4Z/yk03XEteXh79LryYm/9a9CqxjRs3ctEF5zFh/DgaN27Ca28Mol379sydM4fdd+lO\n1647AtBrn33519PPJGMTtp8Pw+UA0tLEE7eexnGXP8WCJasY9frNDP3yZ6bMWlxYplPbZtx04ZEc\n1u9xVv2xnmaN6hYuW79xM/ue8WAyQo+L/Lw83v3nnVz++EAaNmvJ45f8iR69+xQmOoCefU7ggBPP\nBuCXUf/lw6fu57JHX2bxnOlMGDGUW1/5lNXLlvL0DefS//URpKWnZncrmry8PK675ko+/uRzsrKz\n6b3v3vTtewLdd9qpsMzLL75Ao4aNmDRlBm8Peov+t93Ca28MAqBjp058P+7HZIVfLgLS0lKzRZia\nUVVhe/doz8x5y5izYDmbc/N4Z/h4+h6ya5EyF560P/95+ytW/bEegJyVa5IRaoWYO3kiTbPa0bR1\nWzJqZLLH4X35eVTRFvEOdeoVPt+4YV1hK+LnUZ+zx+F9ycisSZPWbWia1Y65kycmNP7yGvPDD3Tq\n1JkOHTuSmZnJqaefwdAhHxUpM3TIR5x97vkA/PnkUxj5xQiC/f+VnGJ4JIknwgRr3bwB85esLJxe\nsGQlWc0aFCnTpV1zurRtzhcvXc+Xr9zIEft3L1y2Q2YGo17/K1++ciPHF0uglcHqZYtp1LxV4XTD\nZq1YnbNkq3Jfvz+Qe884hCH/foiTrwkOCK7OWUKj5q0jXtuS1csWb/XaVLZw4QKys7ecD5yVlc2C\nBQu2LtMmKJORkUH9Bg1Yvjw4+2PO7Nnsu9ceHHHYwYwa9XXiAo8LIZX+SJZK1zWW1I3gQmsDTjGz\nmTG+7nngcTP7VdIcYC8zW1ZxkZYQR5Q/e8X/1qenp9O5bXOO/Mv/kdW8ESNevI6ep/yD1WvW0/XY\nO1iUs5r2WU349Nlr+GXGQmbPT/hmbL8oDZtoP4AD/3weB/75PMZ9/hGfDRzA2f0fhSitomjvZyqL\n1rIrvv0llWnZqhXTZv1GkyZNGD9uHKed8ifGT5xE/fr1KyzeePOucfz8CfjIzPaITIIKlLg9ZnZx\n5FA9ybJg6SqyWzQqnM5q0YiFOau3KjNk5E/k5uYzd+Fyps1ZSue2zQBYFJads2A5X42dzu7dshMX\nfBw0aNaSlUsXFU6vyllE/aYlj5K0x+HH8/Ooz4LXNm/JyqVbrqZalbOY+k1bVFywFSArK5v587eM\nGbBgwXxat269dZl5QZnc3Fx+X72axo0bU7NmTZo0aQLAnj170rFjJ6ZPm5a44OMgVVuEFZYIJbWX\nNFnSc+HgiJ9JqiVp93BEiJ8kfSCpUVh+pKSHJP0gaZqkA6PUeSxwHXCxpP9FrONpYDzQRtK/JY0N\n13l3xGtHSirtGsaEGDtpLp3bNqNd6ybUyEjn1KP25OORPxUpM+R/Ezl4764ANGlYhy7tmjN7wXIa\n1qtFZo2Mwvn77d6RybMqV9ewbbddWTZ/DssXziN38yYmjBhKjwP6FCmTM2924fNfv/sfzbLbA9Dj\ngD5MGDGU3E0bWb5wHsvmz6Fd990SGX657bX33syYMZ05s2ezadMm3hn0Fsf1PaFImeP6nsDrr74C\nwPvvvcvBhx6GJHJycsjLywNg9qxZzJgxnQ4dOyZ8G7ZbCu8jrOiucRfgTDP7i6S3gZOBvwJXm9mX\n4WUxdxIkN4AMM+sVJrw7gSK/EDMbJukZYI2ZPSqpPbAjcIGZXQEgqb+ZrQgHcBwhaVczK5ppkigv\nL5/rH3qbIU9fSXqaeOWj0UyetZi/X34c43/9jY+//JnPv51Mn/26M/69/uTlGbc98SErVq9l3906\n8K/+Z5Jv+aQpjUdf+rzI0ebKID0jg5Ovu4tnbjqf/Px89jn2VFp16MqwF/5J2x13oUfvPnz9/qtM\nG/cNaRkZ1K7XgLNuexSAVh26svuhx/HAeUeRlp7OydffXamOGEOwz++f//cUxx93FHl5eZzf70J2\n2nln7rnrDvbsuRd9jz+BfhdexIX9zmXnbp1p1Kgxr77+FgCjvv6Ke+++g4z0DNLT0/nXgGdo3Lhx\nkrcodiK5rb7SqKKORoVJ6nMz6xJO3wLsAFxkZm3DeZ2Ad8xsT0kjgf5m9o2kFsA3ZtY5Sr13UTQR\n/s/MOkQsvwy4hCDJtyJIum+F9d9kZmNL2kco6ZLwtVCjbs8ddj4/Pm9GJfTgkzcmO4SkunS/DmUX\nquJq1dC4MkaC2SYZTTpa/WPvK7XMytfOjus6Y1XRLcKNEc/zgIYxls8jjE3SS8AewEIzOzbKa9YW\nPJHUAbgJ2DscovtlguQbk3Dcs2cB0mo3rwLnKziXWlK1RZjoo8argZWSDjSzr4FzgS9Le4GZXbAN\n9dcnSIyrw1blMcDI7YzVORdPSd4PWJpknD5zPvCMpNoEY4RtS6IrlZlNlDQBmBTW/U286nbOlY9Q\nyp4+U2GJ0MzmAD0iph+NWLxvlPKHRDxfBrQvod67SlpHOK9fCa+LrD9q3c65iuVdY+ecS8086InQ\nOZcgSt0rSzwROucSxrvGzrlqLZVPqPZE6JxLDIHSPBE656o5bxE656o9T4TOuWovVbvGqXks2zlX\n5ZQ1FmGsrUVJR0uaKmmGpFujLO8nKUfSj+Hj4rLq9Bahcy5hyts1DofXGwAcAcwHxkgaHGXQ5UFm\ndlWs9XqL0DmXMEpTqY8Y9AJmmNksM9tEcNuOE8sblydC51zCxNA1bhqOMF/wuKRYFVnAvIjp+eG8\n4k4OR8F/V1KbKMuL8K6xcy4xFFPXeFkZA7NGq6D42KFDgDfNbGM4UPMrwGGlrdRbhM65hAiG4Sr9\nEYP5QGQLLxtYGFnAzJabWcEgz88BPcuq1BOhcy5hpNIfMRgDdJHUQVImcAYwuOg61Cpi8gRgclmV\netfYOZcw5T1qbGa5kq4ChgPpwItmNim8EdxYMxsMXCPpBCAXWAH0K6teT4TOuYSQID29/CdUm9kw\nYFixeXdEPP8b8LdtqdMToXMuYVL0CjtPhM65xPFrjZ1z1ZpErEeGE84ToXMuQXxgVuec832Ezrlq\nzrvGzrnqTvjBEuec866xc85517iSadO2JbcMuCnZYSTNjbe+lOwQkuqsj29PdghVT2yjzySFJ0Ln\nXEIE+wiTHUV0ngidcwkS81BbCeeJ0DmXMN41ds5Vb7GPOZhwngidcwkhIC0tNceC9kTonEsYbxE6\n56o930fonKvWJD9q7Jxzla9rLKl+aS80s9/jH45zripLS9FMWFqLcBLBjZMjIy+YNqBtBcblnKti\nKuUI1WbWpqRlzjm3PVI0D8Z2g3dJZ0i6LXyeLanMO8c751xxkkp9JEuZiVDSU8ChwLnhrHXAMxUZ\nlHOu6hHBPsLSHjHVIx0taaqkGZJuLaXcKZJM0l5l1RlLi3B/M7sU2ABgZiuAzJgids65CGkq/VEW\nSenAAOAYYCfgTEk7RSlXD7gG+D6muGIos1lSGsEBEiQ1AfJjqdw55wqV0S2OsWvcC5hhZrPMbBPw\nFnBilHL3Ag8TNuDKEksiHAC8BzSTdDcwCngolsqdc66AgPQ0lfoAmkoaG/G4pFg1WcC8iOn54bwt\n65H2ANqY2dBYYyvzhGozGyhpHNAnnHWqmf0S6wqcc65ADI2+ZWZW2j69aDXYlvqVBvwT6LctccV6\nZUk6sDlcYWoOH+GcS3lxODI8H4g8tS8bWBgxXQ/oAYwM19USGCzpBDMbW1KlsRw17g+8CbQOV/qG\npL9tc/jOuWpNiqlrXJYxQBdJHSRlAmcAgwsWmtlqM2tqZu3NrD0wGig1CUJsLcJzgJ5mti7YGN0P\njAMeiCVq55wrUN72oJnlSroKGE7QU33RzCZJugcYa2aDS68hulgS4dxi5TKAWduzMudc9RaPk6bN\nbBgwrNi8O0ooe0gsdZY26MI/CfYJrgMmSRoeTh9JcOTYOediJsXc/U240lqEBUeGJwEfR8wfXXHh\nOOeqshQdfKbUQRdeSGQgzrmqr9KOUC2pE3A/weUsOxTMN7OuFRhXlTZp9Je8+8Td5Ofnc8Dxp3Pk\nuZcXWT7iref5dsgg0tLTqduwCefc9hBNWmYD8OHTD/LLt/8D4Jh+V9OzT9+Ex19eR/TqzKPXHEN6\nmnj54/E8+vrWe1pOPnRn+l9wCGbw84zF9Lv3PXbt3JInb+hLvTo1ycvP5+FXv+LdLyYlYQvK54vP\nh9P/lhvIy8vnnPMv4Job/lpk+caNG7nq0guYOGECjRs35tmXX6dtu/Zs2rSJm669gokTxqG0NO5/\n6HEOOPDgJG3Ftis4oToVxXKw5GXgPuBRguv7LsAvsdtu+Xl5vP3YHVz9xKs0bN6Shy8+kV1696FV\nhy6FZdp02ZlbXhhM5g61+OqD1/hwwINcdO9T/PLtF8yb+gt/e/ljcjdv4okrz2Cn/Q6mVp16Sdyi\nbZOWJp64/jiOu2EgC3J+Z9SzlzB01FSmzM0pLNMpuzE3nX0gh13xAqvWbKBZwzoArNuwmYv+8T4z\n56+gVZN6fPP8pXz+w0xWr4npKqqUkJeXxy03Xss7Hw2jdVY2Rx6yH0cd25cdu225XPb1gS/RoGEj\nfpg4mQ/eHcS9d97Gcy+/wasvB520L0dPICdnKWeefDyfjfwuZe8MF01qpsHYTo6ubWbDAcxsppnd\nTjAajdsOcyZPpFl2O5pmtSWjRiY9Dz+en77+vEiZrj33I3OHWgB02HkPVuUsBmDR7Ol03mMf0jMy\nqFmrNllduvPr6C8Tvg3lsXf3LGYuWMGcRSvZnJvHOyN+oW/vbkXKXNi3J//54AdWhQkuZ9VaAGbM\nX87M+SsAWLT8D3JWrqVpw9qJ3YByGj92DB06dqJ9h45kZmZy0smn8enHQ4qU+fTjIZx+ZjDY0/F/\nOpmvR/4PM2PalMkceHDw02vWrDkNGjTkx/HjEr4N20uKz+gzFSGWRLhRQcd+pqTLJB0PNK/guKqs\nVTmLadS8VeF0w+YtCxNdNN8OGcRO+wbdn+zOQeLbtGE9a1atYNr471i5dFGFxxxPrZvWZ/7S1YXT\nC3JWk9WsaIu2S5smdGnThC8GXMSX/76YI3p13qqevbpnkVkjnVkLVlZ4zPG0eNECsrKzC6dbtc5i\n0cKFJZbJyMigXv0GrFixnJ132ZVPhw0hNzeXuXNmM/HH8SxYMI/KJC1NpT6SJZau8fVAXYIhbe4H\nGgAXVmRQpZF0KnAPsNjMYm6ZSvrWzPaX1B4YamY9KijE0pltNaukHcg/DP+A36b8zHUD3gKg+z4H\nMXfKTzx66cnUa9iYDjvvSXp65br/VrRNLf6WpKen0Tm7CUde8xJZzesz4l8X0rPf04Vd4JZN6vJC\n/z/zl398gEV5P1NZtHiLf/5RyyDOOrcf06dO4YiD96VNm7bs3Ws/MjIq/+efCmIZdKFgPK8/2DI4\na1xJSjezvBiLXwRcYWb/K1ZHhpnllvQiM9u/PDHGS8PmrYq04lYtXUyDpi22KjdlzCg+fWUA1w94\nixqZNQvnH33+VRx9/lUAvHTXtTTLbl/hMcfTgpzfyW7eoHA6q1kDFi77Y6syP0yaT25ePnMXrWLa\nvOV0zm7MuCkLqVe7Ju8/dDZ3Pz+CH36dn+jwy61V62wWzN8S96KFC2jZqlXUMq2zssnNzeWP31fT\nqHFjJHHvg48Wlju2z0F07LR1azlVieR2f0tTYtdY0geS3i/pEesKJLWXNEXSK5J+kvSupNqS5ki6\nQ9Io4FRJnSR9KmmcpK8ldYtS1x1Ab+AZSY9I6ifpHUlDgM8k1ZU0QtJ4ST9LOjHitWu27a2pGO26\n7crS+XNYtnAeuZs3MW7EEHbp3adImXnTJvHmw/257KHnqNeoaeH8/Lw81qwOuoILZkxmwYwpdO91\nYELjL6+xUxbSObsx7Vo1pEZGOqce3oOPv5lSpMyQr6dw8J4dAGjSoDZd2jRh9sKV1MhIZ9D9Z/DG\n8Im8P/LXZIRfbnv03ItZs2Ywd85sNm3axAfvvc1RxxY98n/UsX0Z9OarAAz58D16H3wIkli3bh1r\n1wb7S0d+8V8yMjKKHGRJeaqcXeOn4rieHYGLzOwbSS8CV4TzN5hZbwBJI4DLzGy6pH2Ap4HDIisx\ns3skHQbcZGZjJfUD9gN2NbMVkjKAk8zsd0lNgdGSBluM/adw7LNLABq3aF3ujY4mPSOD066/mwE3\nnEd+Xj779T2V1h27MvS5x2nbbRd2PfAIPhjwABvXr+X526+kIJbLHn6evNxc/nnFaQDsULsu59/x\nT9IrWdcoLy+f658YxpBHzyU9LY1Xhk1g8pwc/n7hoYyfupCPv5nK5z/MoM/enRg/8Ery8o3bnv6M\nFb+v54wjdqX3bu1oXL8W5xy9OwCXPPAhP80oeR9rqsnIyODBR57g9JOOIy8vn7POPZ9u3Xfmwfvu\nYvc9e3L0scdz9nkXcOUl/ei1W3caNWrEf156DYBlOUs5/aTjSEtLo2XrLAY8+1JyN2Y7pOrxbVX0\nPpZwn9xXZtY2nD6MYH/j7sDBZjZXUl0gB5ga8dKaZtY9Sn0jKZoIDzazC8JlNQjGIjuI4BSfHYEO\nZrZY0hozqxvrPsJ23Xa1W17cruu3q4Qbb618P7J4+u3j25MdQtI1r585royxAbdJi8497PRH3y21\nzL9O6h7XdcYqUc2J4tm2YHpt+H8asMrMdo8sFN6foOD8gMElXFi9NuL52UAzgtFyNkuaQ8RJ4M65\n5MpI0SZhosJqK2m/8PmZFBu0wcx+B2aHR4RRYDczyzOz3cNH1NElimkALA2T4KFAu3huhHNu+0mV\n+HaeBSTVLLtUiSYD50v6CWgM/DtKmbOBiyRNJBjoIdoNWcryOrCXpLFhfVPKKO+cS6Dy3sWuosRy\nrXEv4AWC1lZbSbsBF5vZ1duwnnwzu6zYvPaRE2Y2Gzi6rIoixxczs5cJLgEsmF5GcPAk2uvqhv/P\nIRjK2zmXQKl8rXEsLcIngb7AcgAzm4hfYuec2w5pZTySJZaDJWnhkd3IebGe/OwtMOdcoRQ9nzqm\nRDgv7B5beBT3amBaxYblnKtqKusI1QUuJ+getwWWAP8N5znn3DZJ0TwY07XGSwlumeecc9tNkLLX\nGsdy1Pg5tj4hGjO7pEIics4p70XrAAAYRUlEQVRVWSmaB2PqGv834vkOwElA5RoEzTmXfIL0FM2E\nsXSNB0VOS3oV+LyE4s45F1XQNY5DPdLRwP8R3OD9eTN7sNjyy4ArCc5uWQNcYmalDle0PafudMAv\nXXPObYfyXlkSnrkygOD+STsBZ0oqPhbZG2a2Szh2wcPA42XVG8s+wpVs2UeYBqwAbi07ZOec2yJO\nV5b0AmaY2SwASW8RXI5b2OILxy4oUIcoxziKKzURhvcq2Q1YEM7Kj3VsP+ecK0IxHSxpGo4VUOBZ\nM3s2YjqLosco5gP7bLUq6UrgBiCTYuOaRlNqIjQzk/SBmfUsqyLnnCtLDKfPLCtjPMJoFUQ7q2UA\nMEDSWcDtwPmlxlVWVMAPkvaMoZxzzpUo6BqX/ojBfKBNxHQ2sLCEsgBvAX8qq9LS7llS0FrsTZAM\np4b3ApkgaXwMATvnXASRVsYjBmOALpI6SMokuNijyFDykrpETB4HTC+r0tK6xj8AexJDNnXOubKI\n8p9QbWa5kq4ChhOcPvOimU2SdA8w1swGA1dJ6gNsBlZSRrcYSk+EClc8s3yhO+ccIMiIw4mEZjYM\nGFZs3h0Rz6/d1jpLS4TNJN1QSjBlnpvjnHMF4tEirCilJcJ0oC7Rj9I459w2q4yDLiwys3sSFolz\nrkoTkJ6aebDsfYTOORcX4V3sUlFpifDwhEXhnKsWUjMNlpIIzWxFIgNxzlVtQdc4NVNhLOMROudc\nXKRoHvRE6JxLFFXKfYTOORc33jV2zjkq4cGS6i4zPY0ODWonO4ykueDa05MdQlKd+6qPKxJ3lfT0\nGeecixvvGjvnHN41ds45P33GOVe9edfYOecQStHOsSdC51zCpGiD0BOhcy4xJO8aO+ectwidc873\nETrnqjU/auycc3jX2DnnUrZrnJbsAJxz1YMQ6Sr9EVM90tGSpkqaIenWKMtvkPSrpJ8kjZDUrqw6\nPRE65xJDQde4tEeZVUjpwADgGGAn4ExJOxUrNgHYy8x2Bd4FHi6rXk+EzrmEURmPGPQCZpjZLDPb\nBLwFnBhZwMz+Z2brwsnRQHZZlfo+QudcQsR41LippLER08+a2bMR01nAvIjp+cA+pdR3EfBJWSv1\nROicS5yym33LzGyvbazBohaUzgH2Ag4ua6WeCJ1zCROHo8bzgTYR09nAwq3WI/UB+gMHm9nGsir1\nfYTOuYRJU+mPGIwBukjqICkTOAMYHFlA0h7Af4ATzGxpTHFt22Y451w5lPNoiZnlAlcBw4HJwNtm\nNknSPZJOCIs9AtQF3pH0o6TBJVRXyLvGzrmECHJd+U+oNrNhwLBi8+6IeN5nW+v0ROicS4zYu78J\n54nQOZc4ngidc9WbD9XvIowd9QX/efB28vPyOOrksznt4muKLH//lWcY/t7rpKen06BxE6679wla\ntG7DkoXzuP+6C8nPyyM3N5fjz7qI404/P0lbsf12alGHU3driSS+nb2Sz6YtL7L8wA6NOKhTI/IN\nNubm88b4hSz+YxONa9fgjiM7seSPTQDMWbGONycsTsYmlEvPNg24vHc70tLEp78u5e0Ji6KW692x\nMbcf3YWr3/mF6Tlr2SO7Phfu25aMdJGbZzz/3W9MXPB7gqPffsK7xi6Ul5fH0/fdyv3PvU3Tlq25\n7vSj2PfQo2jbacfCMp269+D/Bg1nh1q1+fitl3nxsXv422PP0bhZCx57bSg1Mmuyft1aLv/Twex7\n6FE0ad4yiVu0bQScvnsrnhw1l1XrNnPLYR35adEfLA6TG8CYeav5evZKAHZpVZeTd23JgG9+A2DZ\nmk08MGJWMkKPizTBlQe157YhU1i2ZhNPnrIzo+es4reV64uUq1UjjRN3bcHkxWsK5/2+IZc7h01l\nxbrNtGtci/v7duOcgRMSvQnlk6KJ0E+fSbBpP4+nddsOtGrTnho1MjnomD/x3RefFimzW6/e7FCr\nNgDdduvJsiVBi6FGjUxqZNYEYPOmjVh+fmKDj4P2jWuRs3YTy9duJs9g3PzV7Na6XpEyG3K3bFfN\n9Kr1Fd2xeV0Wrd7A4t83kptvfDljBft1aLRVufN6ZfPOhEVsztvyXsxcto4V6zYDMHfFejIzRI1U\nbWKVQGX8S5aq9S2rBJYvXUzTlq0Lp5u2aM3ypSV374a//wZ7HXhY4XTOogVccdIhnN9nT0656KpK\n1RoEaFgrg5Xhjxlg5fpcGtSqsVW5gzo24u6jOnPSLi14e+KW96dJnUz+dngHrj+oHZ2a1E5IzPHU\npE4mOWu2tH6XrdlEkzpFt79T09o0q1uTH+auKrGe3h0bMzNnHZvzo15dlrLicEJ1xcSVvFVvP0nX\nSJos6fUYy7eW9G74/BBJQys2wpKZbf3FLek69C+GvMv0ST9yygVXFs5r1iqLpz8YyfPDRjPio0Gs\nXBbTifOpLcpv+atZK7lz+Aw++GUJx3RrCgRdw9s/mc4DI2bz7k9LuLBXFjtkVK6vcLTPOvIrIeDS\nA9rx3LdzS6yjXaNaXLhfG578cnb8A6xIZZ1M7Ylwm10BHGtmZxfMkFTi/k4zW2hmpyQksjI0bdGK\nZYu3XBq5bMlCGjfbulU34bsvGfTsE9z5r4GF3eFITZq3pG3nbkwa/32Fxhtvq9bn0qj2lhZQo1oZ\nrN6wucTy4+b9Xth1zs031m7KA2Deqg3krN1E87qZFRtwnC1bs4lmETE3rZtZ2N0FqJWZTrvGtXj4\nxJ145Zzd6daiLncd25UuzeoE5etk8vdjuvDoiJks+r3MS2hTjneN40TSM0BHYLCk1ZKelfQZMFBS\ne0lfSxofPvYPX9Ne0i9JDTzUtcceLPxtFovnz2Xz5k189cmH7HvoUUXKzJz8M/+6+2bueGogDZs0\nK5y/bPFCNm4Idqr/sXoVv074gaz2nRIaf3nNXbme5nUzaVK7BumCntkN+GnhmiJlIhNFj1Z1WRp2\nJetmphf+VJrUqUHzupksW7uJymTq0jW0brADLerVJCNNHNy5MaPDA0MA6zblcfpL4zn/tR85/7Uf\nmbJkDXcNm8b0nLXUyUznnuO68tLoefy6eE0pa0lNBUeNU7FrXOmOGpvZZZKOBg4luObweKC3ma2X\nVBs4wsw2SOoCvEkwDE9MJF0CXALQvFWZYzlul/SMDC6/7QFuv/QM8vPyOPKkM2nXuRuvPvUQXXbe\njX0PPZoXHrubDevW8sANFwNBd/jOp17lt1nTef6RO5GEmXFyv8vp0LX44LypLd9g0I+Luap3W9Ik\nvpuzikV/bKTvTs2Yu3I9Py9awyGdGrFj8zrk5cP6TXkMHBO0oDs3rU3fnZuRnw/5Zrw5YRHrNleu\nA0b5Bk9/PYf7j9+RNInPpuQwd+V6zt07i+k5axk9p+T9gifs0oLWDXbgrL2yOGuvLABuGzKF1etz\nExV++aXosR1F22eV6iTNIUhwVwFmZneH8xsATwG7A3lAVzOrLak9MNTMekg6BLjJzPqWto4uO+9u\nT779WYVtQ6obMmVZskNIqllL/kh2CEk3/Mp9x5UxNuA26bHbnvbup6NKLdO9dZ24rjNWla5FGMXa\niOfXA0uA3Qi6/RuSEpFzLqpUPdun0u0jLEMDYJGZ5QPnAulJjsc5F8mPGifE08D5kkYDXSnaWnTO\nJVHBMFypeNS4UnaNzax9+PSuYvOnA7tGzPpbOH8O0CN8PhIYWbEROue24sNwOeccKXvU2BOhcy5B\nfBgu51w158NwOecceNfYOee8a+ycq/a8a+ycq95U8pBzyVbVTqh2zqW08l9aIuloSVMlzZB0a5Tl\nB4WjT+VKimn4PU+EzrmEiMcwXJLSgQHAMcBOwJmSig/B9BvQD3gj1ti8a+ycS5g4dI17ATPMbFZQ\nn94CTgR+LSgQXkmGpJjHaPMWoXMuYWK41rippLERj0uKVZEFzIuYnh/OKxdvETrnEiaGFuGyMsYj\njFZDuQdV9UTonEsIxeeo8XygTcR0NrCwhLIx866xcy5h4jAM1xigi6QOkjKBM4DB5Y3LE6FzLmEK\nWoUlPcpiZrkEt+gYDkwG3jazSZLukXRCsA7tLWk+cCrwH0mTyqrXu8bOuYSJxwnVZjYMGFZs3h0R\nz8cQdJlj5onQOZcgPgyXc66aE6l7iZ0nQudcwngidM5Ve941ds5Vbyk8+ownQudcQvg+Quecw7vG\nzjnnLULnnPNE6Jyr9lK1ayyzco9gUyVJygHmJjGEpsCyJK4/FVT39yDZ29/OzJrFqzJJnxJsU2mW\nmdnR8VpnrDwRpihJY8sYl63Kq+7vQXXf/kTy0Wecc9WeJ0LnXLXniTB1PZvsAFJAdX8Pqvv2J4zv\nI3TOVXveInTOVXueCJ1z1Z4nQudSmKT08P/UPBO5ivBEWIlJOlDSQcmOI1kktZd0aLLjqCiSugEv\nSWpkZubJsOJ4IqzcugJvS+qd7ECSpBfwqqQjkh1IBfkd+AN4VFJDT4YVxxNhJRTernBnM3sBuBV4\nWdKByY4rUSR1kdTazN4GbgIel3RksuOKF0l7Sfq7mS0EHgbWAP/nybDieCKsnHYFVoVdppeB+wm6\nUNUlGR4KdJJUw8zeAh4BHqtCyXAm8Lyk3cxsLvAPYBWeDCuMn0dYSYX7j54HbjKz0ZIuAPoD/cxs\nVHKjq3iSWgA/A/ua2SxJ5wE3AzeY2efJja78JGUCnwG/mdl54fbeBtQl+MxXJjXAKsZbhJVE8RaA\nmU0BPgdul9TLzF4C7gUGS9ovGTEmkpktAQYCIyW1N7OBwEPAs5KOSm502y7K57sJOAVoIOn5cHv/\nARhwv7cI48tbhJWAJFn4QUk6nKBVMMLM1ki6GTgMuMPMxkg6C/jBzGYkMeS4K3gPJHUC6pjZT+H8\nu4FLgP3MbI6kfsBMM/s6ieFuk2Kfbz+CcULNzF6Q1Bh4FZhvZpdKak7wu12SvIirHk+ElYik64GT\ngelAc+ARMxsp6QaC1sNVZjY+mTFWJEnHERw8GAN0Av5kZssl3QH8FdjFzGaHZQuTS2Uh6VrgNIJd\nHEOAB83s/jAZfgRMMLNrkhljVeUjVKewYi2FI4A+ZtZb0q3A/sD5YZHHJW2iCg9iKqknQRI8muC0\nmdeA9ySdbmb3SKoBdARmQ9CcSlqwMQi7tjKz/HA6GzgCOBa4CPgOuF5SXTP7m6QTCHoCrgJ4izBF\nFUuCBwDzw0UHAP2AE4CXgM7ALWb2RTLirCgF+8DC7nB3gu1vD7QgOEp+BPA6QcvwcDNbVPC6VE+C\nAGGCWxM+Pw+YB0wg+APX38wOkHQM8DHB5/tI8qKt+vxgSQqSVC8iCR4FPAasCE+l2BEYZmYbgC+B\nqQRHT6sMSRkWCv8IvAG0MLOfgUOA983s93B+HsFuAiD1W4IAYevuifD5EcAZwM9mtorgN/l9WLQ2\nwQGgwcmIszrxrnGKkXQScEp4Osw+wL8JTon5IyzyHTBAUldgb+AMM8tJTrTxJ2kXgpPEzw4PjNwK\n3BZx8GcKcLSkvxK0CvuZ2cTkRLvtJDUBrgGukHQmcDEwxswKdmtsBFpJepXg8z0q/APoKpB3jVOI\npLrAewRHCScAa4EPCY4Y9g3L1AB6A32AgWY2NUnhxp2kWsCbBC2gwcAxBEeE5wAXmFlueP5kwfa/\nZmZDkxTudpFUD3gHWEqQ6L4m6O4/WnCkW9K+QCOCo9/TkhVrdeKJMMVIugzoS3Ad8c4EP4jXgDlm\ndkkyY6tokuoADxB0d7sBNwCtCY6IzwIeN7O8sGzB6TSVYp9gpLA1eydwl5k9Iuk+gt7Zx5XptJ+q\nxPcRpp5cgi7xJwT7xZYC5wEtJL2Z1MgqmJmtBX4i6C5ONbPJBC2mj4Fs4DaFw1IVJL/KlgRDg4AT\ngYskXQQMADYAp4etQZdgnghTz0jgVIJTYS4LrzddDFwOpEtqlczgEmAacBnQTdKVQD7wKfAFQeuw\nXRJjiwszm2tm/wXOItgHeiTwHLCQoOXrEsy7xikmosu3K3AuwcgjQ81snKT0gq5hVRWx/QcA9wFv\nEVxTLaBRVTowBCBpN4IkfzUwqKp/vqnKE2GSRNu3FY6mslnSnkAOUI+gJbiQYP/YxiSEmjCSaprZ\nRklNCVqCHYCnCQ4KDUhudBUnPFK+vqpdFlmZeCJMgmInS7cHNkacEHwAQTfpivDyuV2BxeG+wioj\nouXXDFgX7h9EUkeC21g+YWZDFQw6u9nMvi+tPufKwxNhghVLgjcQXE41A/jFzPpLegD4prKdFrI9\nJB0L/B34AWhlZqdJeg6YbWb/SG50rjrxE6oTLCIJ7gPsSXCqTCbBkPPrzexv4fIMIK+SHhUtU3jt\n8H0EV1UcAxweLrrczHLDMmkF1+I6V5H8qHGCKbAbQfd3E8HAm1MJzpU7XtK/Acwst6olwYLrhyXV\nBjYTjJ/YleDo6fFhsb0KynsSdIniiTABChIABC3C8JKwR4EuwL7hQZLfCFpH3SQ1j3xNVRHuEzyc\n4JSRtgSXDz4AHGhmsxXcke86BaMxO5cw3jVOgIju8NkEyW8pwdUim4G7gHskjQ6TwREFXcOqRtLu\nBJfGDTGzbyXdTzCO4B6SOhAMRd/ffNBRl2B+sCRBwpODzyW4lrYjwZh6xxGMP3cVcL2ZfZe8CCtG\n5KVwwDiCKyj6AdPD+VcRDD2VC7xhZp9WxsvmXOXmibCCFL8WVtIzwItm9kO4/Dago5ldHCbJIWH3\nuMoJT4GpTzC4wG3Ak2b2r4jlRQYpdS7RfB9hBSjWoukSjhiTTTCWXoGhhO+/mQ2oakkw4sDIvgQn\nRZ9NMJBCDvD3sCUIFO439SToksb3EcZZsfMErwKuAz4AJgLXSFpmZi8CuwDtJTUEVle1rmDYCu5F\nMJr0X8zse0mdgd8IusK3SWpmZncmNVDn8EQYdxFJ8ASCG7EfRXBRfX3gv8B9kvYguEn56RaMSlxV\nNSBoBR9OMOryXIIh6WcCtwNZSYvMuQjeNa4AkrKAp4AMM5sJvEiQACYT3Iv3n8DBZjYpeVFWPAtu\ntP5n4EJJZ5rZZmAVwUnkK8xsVFU8TchVPn6wpIJI+jNBMrzBzN6SlEZwtLQz8HAVbwkWIel4ghst\nfQKsA96rDpcQusrDE2EFUnAf3geAf0Qkwzq25f4j1Ua4q+AuguH1Hy9oCVa1faOucvJ9hBXIzD6W\nlA88KynXzN4Fql0SBDCzwZI2AC9KmmNm7yc7JucKeIswARTcsnGmmVX70Yf9vXCpyBOhc67a86PG\nzrlqzxOhc67a80TonKv2PBE656o9T4TOuWrPE6EDQFKepB8l/SLpnXA4/e2t6xBJQ8PnJ0i6tZSy\nDSVdsR3ruEvSTbHOL1bmZUmnbMO62kv6ZVtjdJWHJ0JXYL2Z7W5mPQjupXJZ5MLwXivb/H0xs8Fm\n9mApRRoC25wInYsnT4Qumq+BzmFLaLKkp4HxQBtJR0r6TtL4sOVYF0DS0ZKmSBpFMNAC4fx+kp4K\nn7eQ9IGkieFjf+BBoFPYGn0kLHezpDGSfpJ0d0Rd/SVNlfRfYMeyNkLSX8J6Jkp6r1grt4+kryVN\nk9Q3LJ8u6ZGIdV9a3jfSVQ6eCF0RCm4jegzwczhrR2Cgme0BrCUYPquPme0JjAVukLQDwV35jgcO\nBFqWUP2TwJdmthvBrUwnEdzIaWbYGr1Z0pEE93XpBewO9JR0kILbf54B7EGQaPeOYXPeN7O9w/VN\nJriHdIH2wMEEt0t4JtyGiwjGhtw7rP8v4b1UXBXn1xq7ArUk/Rg+/xp4AWgNzDWz0eH8fYGdgG/C\nMRMyge8IRp6ebWbTASS9BlwSZR2HAecBmFkesFpSo2JljgwfE8LpugSJsR7wgZmtC9cxOIZt6iHp\nPoLud11geMSyt8NRsadLmhVuw5HArhH7DxuE654Ww7pcJeaJ0BVYb2a7R84Ik93ayFnA52Z2ZrFy\nuwPxulZTwANm9p9i67huO9bxMvAnM5soqR9Fb5VQvC4L1321mUUmTCS138b1ukrGu8ZuW4wGDgiH\n3EdSbUldgSlAB0mdwnJnlvD6EcDl4WvTJdUnGI2nXkSZ4QQDuRbse8yS1Bz4CjhJUi1J9dhyQ/jS\n1AMWKbhnzNnFlp0qKS2MuSMwNVz35WF5JHWVVCeG9bhKzluELmZmlhO2rN6UVDOcfbuZTZN0CfCx\npGXAKKBHlCquJRiS7CIgD7jczL6T9E14eson4X7C7sB3YYt0DXCOmY2XNAj4kWDI/69jCPnvbLlF\nwM8UTbhTgS8J7qx3mZltkPQ8wb7D8eF4iTnAn2J7d1xl5qPPOOeqPe8aO+eqPU+EzrlqzxOhc67a\n80TonKv2PBE656o9T4TOuWrPE6Fzrtr7fzoN37XZKAxuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c65d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history[\"acc\"][-1])\n",
    "\n",
    "# TRAIN SET\n",
    "preds = model.predict(final_X_train)\n",
    "\n",
    "# decode one-hot to single labels\n",
    "preds = [ np.argmax(pred, axis = 0) for pred in preds ]\n",
    "labels = [ np.argmax(label, axis = 0) for label in y_train_one_hot ]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(labels, preds)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"non-frail\", \"pre-frail\", \"frail\"], normalize=True,\n",
    "                      title='Normalized confusion matrix - Train set - 3 Autoencoders')\n",
    "\n",
    "# TEST SET\n",
    "preds = model.predict(final_X_test)\n",
    "\n",
    "# decode one-hot to single labels\n",
    "preds = [ np.argmax(pred, axis = 0) for pred in preds ]\n",
    "labels = [ np.argmax(label, axis = 0) for label in y_test_one_hot ]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"non-frail\", \"pre-frail\", \"frail\"], normalize=True,\n",
    "                      title='Normalized confusion matrix - Test set - 3 Autoencoders')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
